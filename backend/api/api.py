from fastapi import FastAPI, UploadFile, File, Form, Request, BackgroundTasks, Header
# import pandas as pd  # pandas ì—†ì´ ì‘ë™í•˜ë„ë¡ ì£¼ì„ ì²˜ë¦¬
import io
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from bs4 import BeautifulSoup
from typing import List, Dict, Any
import requests

import os
import re
import shutil
import logging
import json
import time
from datetime import datetime


from ..utils.config import STATIC_DIR, DOCS_DIR, LOG_DIR, CHROMA_DIR
from ..data.database import (
    get_vectordb,
    index_document,
    get_indexed_files,
    remove_document,
    reset_vectordb,
    save_feedback_to_file,
    get_feedback_vectordb,
    index_json_data
)
# semantic_search ëª¨ë“ˆ ì œê±°ë¨
from ..utils.slack import clean_mention, post_slack_reply, handle_slack_message
from ..utils.utils import format_sources

# qa_utils ëª¨ë“ˆ ì œê±°ë¨
from ..services.category_classifier import auto_classify
from slack_sdk.web.async_client import AsyncWebClient
from ..services.effort_estimation import EffortEstimation, effort_manager
from ..services.effort_qa import run_effort_qa_chain, run_effort_qa_with_feedback, get_effort_statistics, search_similar_features
from ..data.database import get_vectordb, index_document, index_json_data, index_json_data_incremental
from ..services.jira_integration import create_jira_integration
from ..services.mock_qa import mock_qa_response, mock_effort_qa_response
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from data.prompts import intent_prompt_manager
# from apscheduler.schedulers.background import BackgroundScheduler  # SSL ë¬¸ì œë¡œ ì„ì‹œ ë¹„í™œì„±í™”

# Configure logging
from ..utils.config import LOG_DIR

# ë¡œê·¸ ë””ë ‰í† ë¦¬ í™•ì¸
os.makedirs(LOG_DIR, exist_ok=True)

# ë¡œê·¸ íŒŒì¼ ì„¤ì • (ì¬ê¸°ë™ ì‹œ ì´ˆê¸°í™”)
log_file = os.path.join(LOG_DIR, "app.log")

# íŒŒì¼ í•¸ë“¤ëŸ¬ (ì¬ê¸°ë™ ì‹œ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ mode='w' ì‚¬ìš©)
file_handler = logging.FileHandler(log_file, mode='w', encoding="utf-8")
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
file_handler.setFormatter(file_formatter)

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
console_handler.setFormatter(console_formatter)

# ë£¨íŠ¸ ë¡œê±° ì„¤ì •
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)
root_logger.addHandler(file_handler)
root_logger.addHandler(console_handler)

logger = logging.getLogger(__name__)
logger.info(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ì„¤ì • ì™„ë£Œ: {log_file}")

# ì „ì—­ ë™ê¸°í™” ìƒíƒœ ë³€ìˆ˜
sync_status = {
    "is_running": False,
    "progress": 0,
    "total_epics": 0,
    "completed_epics": 0,
    "failed_epics": 0,
    "current_epic": "",
    "message": "",
    "failed_list": []
}

# Create FastAPI app
app = FastAPI()

# ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” (SSL ë¬¸ì œë¡œ ì„ì‹œ ë¹„í™œì„±í™”)
# scheduler = BackgroundScheduler()

# ê¸°ì¡´ ê´€ë¦¬ì í˜ì´ì§€ ì œê±°ë¨

@app.get("/")
async def root():
    """ë©”ì¸ í˜ì´ì§€ - effort-managementë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/effort-management/effort-management.html")

@app.get("/effort")
async def effort_management():
    """ê¸°ì¡´ /effort ê²½ë¡œ - effort-managementë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/effort-management/effort-management.html")

@app.get("/static/effort-management.html")
async def static_effort_redirect():
    """ê¸°ì¡´ /static ê²½ë¡œ - effort-managementë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/effort-management/effort-management.html")

@app.on_event("startup")
async def startup_event():
    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘...")
        logger.info("=" * 80)
        
        # ë²¡í„° DB ìƒ‰ì¸ ìŠ¤í‚µ (ë™ê¸°í™” ì‹œ ì¦ë¶„ ìƒ‰ì¸ìœ¼ë¡œ ì²˜ë¦¬)
        logger.info("ğŸ“š [1/3] ë²¡í„° DB ìƒ‰ì¸ í™•ì¸...")
        try:
            json_file_path = os.path.join(DOCS_DIR, "effort_estimations.json")
            if os.path.exists(json_file_path):
                # JSON íŒŒì¼ ì •ë³´ í™•ì¸
                import json
                with open(json_file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    total_items = len(data)
                
                logger.info(f"   ğŸ“„ effort_estimations.json íŒŒì¼ í™•ì¸: {total_items}ê°œ í•­ëª©")
                logger.info(f"   â„¹ï¸ ìƒ‰ì¸ì€ Epic ë™ê¸°í™” ì‹œ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ì¦ë¶„ ìƒ‰ì¸)")
                logger.info(f"   â„¹ï¸ ìˆ˜ë™ ì¬ìƒ‰ì¸ì´ í•„ìš”í•˜ë©´ ì›¹ UIì—ì„œ 'ë°ì´í„° ì¬ìƒ‰ì¸' ë²„íŠ¼ í´ë¦­")
            else:
                logger.warning("   âš ï¸ effort_estimations.json íŒŒì¼ ì—†ìŒ")
        except Exception as check_error:
            logger.error(f"   âŒ íŒŒì¼ í™•ì¸ ì‹¤íŒ¨: {str(check_error)}")
        
        # ì¹´í…Œê³ ë¦¬ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
        logger.info("ğŸ“‚ [2/3] ì¹´í…Œê³ ë¦¬ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
        await auto_migrate_categories()
        logger.info("   âœ… ì¹´í…Œê³ ë¦¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        
        # Epic ìë™ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (SSL ë¬¸ì œë¡œ ì„ì‹œ ë¹„í™œì„±í™”)
        logger.info("â° [3/3] ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì¤‘...")
        # scheduler.add_job(
        #     sync_completed_epics_background,
        #     'cron',
        #     hour=3,
        #     minute=0,
        #     id='auto_sync_completed_epics',
        #     replace_existing=True
        # )
        # scheduler.start()
        logger.info("   âš ï¸ Epic ìë™ ë™ê¸°í™” ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„í™œì„±í™” (SSL ë¬¸ì œ)")
        logger.info("   â„¹ï¸ ìˆ˜ë™ ì‹¤í–‰ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        logger.info("=" * 80)
        logger.info("âœ… ì„œë²„ ê¸°ë™ ì™„ë£Œ! ğŸ‰")
        logger.info("=" * 80)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"âŒ Error during startup: {str(e)}")

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ë¦¬"""
    try:
        # scheduler.shutdown()  # SSL ë¬¸ì œë¡œ ì„ì‹œ ë¹„í™œì„±í™”
        logger.info("âœ… ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ì„œë²„ ì¢…ë£Œ ì˜¤ë¥˜: {str(e)}")

async def auto_migrate_categories():
    """ì¹´í…Œê³ ë¦¬ ë³€ê²½ ì‹œ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    try:
        logger.info("ğŸ“Š ì¹´í…Œê³ ë¦¬ ë³€ê²½ ê°ì§€ ì¤‘...")
        
        # í˜„ì¬ ì¹´í…Œê³ ë¦¬ ë¡œë“œ
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        current_categories = category_manager.get_categories()
        
        # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ íŒŒì¼ ë¡œë“œ (categories.json)
        import os
        categories_file = os.path.join(DOCS_DIR, "categories.json")
        
        if not os.path.exists(categories_file):
            logger.warning("ì¹´í…Œê³ ë¦¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ëª¨ë“  ê³µìˆ˜ ì‚°ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        estimations = effort_manager.get_all_estimations()
        
        # ì¹´í…Œê³ ë¦¬ ë³€ê²½ ê°ì§€ ë° ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
        updated_count = 0
        reset_count = 0
        
        for estimation in estimations:
            if not estimation.major_category or not estimation.minor_category or not estimation.sub_category:
                continue
            
            # í˜„ì¬ ì¹´í…Œê³ ë¦¬ êµ¬ì¡°ì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            major = estimation.major_category
            minor = estimation.minor_category
            sub = estimation.sub_category
            
            # ëŒ€ì¤‘ì†Œë¶„ë¥˜ê°€ ëª¨ë‘ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            is_valid = (
                major in current_categories and
                minor in current_categories.get(major, {}) and
                sub in current_categories.get(major, {}).get(minor, [])
            )
            
            if is_valid:
                # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°: ê·¸ëŒ€ë¡œ ìœ ì§€ (ë³€ê²½ ì—†ìŒ)
                logger.debug(f"âœ… ì¹´í…Œê³ ë¦¬ ìœ ì§€: {major} > {minor} > {sub}")
            else:
                # í•˜ë‚˜ë¼ë„ ì•ˆ ë§ëŠ” ê²½ìš°: ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™” (ì‚¬ìš©ìê°€ ë‹¤ì‹œ ì„ íƒí•˜ë„ë¡)
                logger.info(f"ğŸ”„ ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™”: {major} > {minor} > {sub} -> (ì´ˆê¸°í™”ë¨, ì¬ì„ íƒ í•„ìš”)")
                estimation.major_category = None
                estimation.minor_category = None
                estimation.sub_category = None
                reset_count += 1
        
        if reset_count > 0:
            # ë³€ê²½ì‚¬í•­ ì €ì¥
            effort_manager.save_data()
            logger.info(f"âœ… ì¹´í…Œê³ ë¦¬ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {reset_count}ê°œ ë°ì´í„° ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™” (ì¬ì„ íƒ í•„ìš”)")
        else:
            logger.info("ğŸ“Š ì¹´í…Œê³ ë¦¬ ë³€ê²½ ì‚¬í•­ ì—†ìŒ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ì •í™•íˆ ì¼ì¹˜í•¨)")
        
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}")

@app.post("/upload_pdf/")
async def upload_pdf(file: UploadFile = File(...)):
    try:
        file_path = os.path.join(DOCS_DIR, file.filename)
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
            
        if index_document(file_path, "pdf"):
            return {"message": f"'{file.filename}' indexed successfully"}
        else:
            return JSONResponse(status_code=500, content={"error": "Failed to index document"})
            
    except Exception as e:
        logger.error(f"âŒ Error uploading PDF: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

def extract_questions(text: str) -> set:
    """Q1:, Q2: í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì§ˆë¬¸ ì¶”ì¶œ"""
    return set(
        m.strip()
        for m in re.findall(r"Q\d+:\s*(.+?)(?:\n|$)", text)
    )


@app.post("/upload_text/")
async def upload_text(text: str = Form(...), source: str = Form(...)):
    try:
        # 1. ì…ë ¥ê°’ ê²€ì¦
        if not text.strip():
            return JSONResponse(status_code=400, content={"error": "í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."})

        safe_source = re.sub(r'[\\/]', '_', source.strip()) or "TEMP"
        txt_filename = f"{safe_source}.txt"
        txt_path = os.path.join(DOCS_DIR, txt_filename)

        logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ì—…ë¡œë“œ ìš”ì²­ - source: {safe_source}")

        # 2. ì¤‘ë³µ ì§ˆë¬¸ í•„í„°ë§
        new_questions = extract_questions(text.strip())
        existing_text = ""
        existing_questions = set()

        if os.path.exists(txt_path):
            with open(txt_path, "r", encoding="utf-8") as f:
                existing_text = f.read()
                existing_questions = extract_questions(existing_text)

        duplicated = new_questions & existing_questions
        if duplicated:
            return JSONResponse(
                status_code=200,
                content={
                    "message": "ì¼ë¶€ ë˜ëŠ” ì „ì²´ ì§ˆë¬¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.",
                    "duplicated_questions": list(duplicated)
                }
            )

        # 3. í…ìŠ¤íŠ¸ íŒŒì¼ì— append ì €ì¥
        with open(txt_path, "a", encoding="utf-8") as f:
            if existing_text:
                f.write("\n")
            f.write(text.strip())

        # 4. ìƒ‰ì¸ ì²˜ë¦¬ (database.pyì˜ index_document í˜¸ì¶œ)
        if index_document(txt_path, file_type="txt", force=True):
            logger.info(f"âœ… '{safe_source}' í…ìŠ¤íŠ¸ ìƒ‰ì¸ ì™„ë£Œ")
            return {
                "message": f"'{safe_source}' í…ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ê³  ì¬ìƒ‰ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
            }
        else:
            return JSONResponse(status_code=500, content={"error": "ë¬¸ì„œ ìƒ‰ì¸ ì‹¤íŒ¨"})

    except Exception as e:
        logger.error(f"âŒ upload_text ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/indexed_files/")
async def get_indexed_files_endpoint():
    try:
        files = get_indexed_files()
        # Add download URLs for each file
        files_with_urls = [
            {
                "filename": filename,
                "download_url": f"/download/{filename}"
            }
            for filename in files
        ]
        return {"indexed_files": files_with_urls}
    except Exception as e:
        logger.error(f"âŒ Error getting indexed files: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/download/{filename}")
async def download_file(filename: str):
    try:
        # Validate file extension
        if not filename.endswith((".pdf", ".txt")):
            return JSONResponse(
                status_code=400,
                content={"error": "Only .pdf and .txt files are supported"}
            )
            
        file_path = os.path.join(DOCS_DIR, filename)
        
        if not os.path.exists(file_path):
            return JSONResponse(
                status_code=404,
                content={"error": f"File '{filename}' not found"}
            )
            
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type="application/octet-stream"
        )
            
    except Exception as e:
        logger.error(f"âŒ Error downloading file: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )

@app.post("/ask/")
async def ask_question(question: str = Form(...)):
    try:
        logger.info(f"ğŸ’¬ Question received: {question}")
        
        # ì¼ë°˜ ì§ˆë¬¸ì€ ëª¨ì˜ ì‘ë‹µ ì‚¬ìš©
        result = mock_qa_response(question)

        if "error" in result:
            return JSONResponse(status_code=400, content={"error": result["error"]})
        
        sources_text = format_sources(result["sources"])

        return {
            "question": result["question"],
            "answer": result["answer"],
            # "sources": result["sources"],
            "formatted_response": f"{result['answer']}{sources_text}"
        }

    except Exception as e:
        logger.error(f"âŒ Error processing question: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/slack/test")
async def slack_test():
    """ìŠ¬ë™ë´‡ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    return {"status": "success", "message": "ìŠ¬ë™ë´‡ì´ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!"}

@app.post("/slack/test")
async def slack_test_post(request: Request):
    """ìŠ¬ë™ URL ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    try:
        data = await request.json()
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ POST ìš”ì²­ ìˆ˜ì‹ : {data}")
        
        if data.get("type") == "url_verification":
            challenge = data.get("challenge")
            logger.info(f"ğŸ” í…ŒìŠ¤íŠ¸ URL ì¸ì¦ - Challenge: {challenge}")
            return {"challenge": challenge}
        
        return {"status": "success", "received": data}
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ POST ì˜¤ë¥˜: {str(e)}")
        return {"status": "error", "message": str(e)}

@app.post("/slack/events")
async def slack_event_listener(
    request: Request,
    background_tasks: BackgroundTasks,
    x_slack_retry_num: str = Header(default=None),
    x_slack_retry_reason: str = Header(default=None)
):
    try:
        # ìš”ì²­ ë¡œê¹…
        logger.info(f"ğŸ”” Slack ì´ë²¤íŠ¸ ìˆ˜ì‹  - Retry: {x_slack_retry_num}, Reason: {x_slack_retry_reason}")
        
        data = await request.json()
        logger.info(f"ğŸ“¦ ìˆ˜ì‹ ëœ ë°ì´í„°: {data}")

        # ì¤‘ë³µ ì „ì†¡ ë°©ì§€
        if x_slack_retry_num:
            logger.info("â­ï¸ ì¤‘ë³µ ìš”ì²­ìœ¼ë¡œ ì¸í•œ ìŠ¤í‚µ")
            return {"status": "ok"}

        # Slack URL ì¸ì¦
        if data.get("type") == "url_verification":
            challenge = data.get("challenge")
            logger.info(f"ğŸ” URL ì¸ì¦ ìš”ì²­ - Challenge: {challenge}")
            return {"challenge": challenge}

        # ì‹¤ì œ ì´ë²¤íŠ¸ ì²˜ë¦¬
        if data.get("type") == "event_callback":
            event = data.get("event", {})
            event_type = event.get("type")
            user = event.get("user", "ì•Œ ìˆ˜ ì—†ìŒ")
            
            logger.info(f"ğŸ“¨ ì´ë²¤íŠ¸ íƒ€ì…: {event_type}, ì‚¬ìš©ì: {user}")

            # ì•± ë©˜ì…˜
            if event_type == "app_mention":
                channel = event.get("channel")
                thread_ts = event.get("thread_ts", event.get("ts"))
                text = clean_mention(event.get("text", ""))
                logger.info(f"ğŸ“¥ ì±„ë„ ìˆ˜ì‹ ëœ ë©”ì‹œì§€ {user}: {text}")
                background_tasks.add_task(handle_slack_message, text, channel, thread_ts, event.get("ts"))

            # DM ë©”ì‹œì§€
            elif event_type == "message" and event.get("channel_type") == "im" and not event.get("bot_id"):
                channel = event.get("channel")
                text = clean_mention(event.get("text", ""))  # ë©˜ì…˜ ì œê±° ì¶”ê°€
                logger.info(f"ğŸ“¥ ì•± ë©”ì„¸ì§€ íƒ­ ìˆ˜ì‹ ëœ ë©”ì‹œì§€ {user} : {text}")
                background_tasks.add_task(handle_slack_message, text, channel, None, event.get("ts"))
            
            # ì´ëª¨ì§€ ë¦¬ì•¡ì…˜ ì´ë²¤íŠ¸ (í”¼ë“œë°± ìˆ˜ì§‘)
            elif event_type == "reaction_added":
                logger.info(f"ğŸ‘ reaction_added ì´ë²¤íŠ¸ ìˆ˜ì‹ ! reaction={event.get('reaction')}, item={event.get('item')}")
                from ..utils.slack import handle_slack_reaction
                background_tasks.add_task(handle_slack_reaction, event)
            
            else:
                logger.info(f"â„¹ï¸ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ íƒ€ì…: {event_type}")

        logger.info("âœ… Slack ì´ë²¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ")
        return {"status": "ok"}

    except Exception as e:
        logger.error(f"âŒ Error handling Slack event: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})





@app.delete("/files/{filename}")
async def delete_file(filename: str):
    try:
        # Validate file extension
        if not filename.endswith((".pdf", ".txt")):
            return JSONResponse(
                status_code=400,
                content={"error": "Only .pdf and .txt files are supported"}
            )
            
        file_path = os.path.join(DOCS_DIR, filename)
        
        if remove_document(file_path):
            return {"message": f"File '{filename}' deleted successfully"}
        else:
            return JSONResponse(
                status_code=404,
                content={"error": f"File '{filename}' not found"}
            )
            
    except Exception as e:
        logger.error(f"âŒ Error deleting file: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )

@app.post("/indexed_files")
async def reindex_all_files():
    try:
        logger.info("ğŸ”„ Starting complete reindexing process...")
        
        # First, reset the Chroma DB
        if not reset_vectordb():
            return JSONResponse(
                status_code=500,
                content={"error": "Failed to reset database"}
            )
        
        logger.info("ğŸ—‘ï¸ Database reset complete, starting reindexing...")
        indexed_count = 0
        error_count = 0
        
        # Get list of all files
        for filename in os.listdir(DOCS_DIR):
            if filename.endswith((".pdf", ".txt")):
                file_path = os.path.join(DOCS_DIR, filename)
                file_type = "pdf" if filename.endswith(".pdf") else "txt"
                
                try:
                    # No need for force=True since DB is fresh
                    if index_document(file_path, file_type):
                        indexed_count += 1
                        logger.info(f"âœ… Indexed: {filename}")
                    else:
                        error_count += 1
                        logger.error(f"âŒ Failed to index: {filename}")
                except Exception as e:
                    error_count += 1
                    logger.error(f"âŒ Error indexing {filename}: {str(e)}")
        
        message = f"ì „ì²´ ì¬ìƒ‰ì¸ ì™„ë£Œ: {indexed_count}ê°œ ì„±ê³µ"
        if error_count > 0:
            message += f", {error_count}ê°œ ì‹¤íŒ¨"
            
        logger.info(message)
        return {"message": message}
        
    except Exception as e:
        error_msg = f"âŒ Error during reindexing: {str(e)}"
        logger.error(error_msg)
        return JSONResponse(status_code=500, content={"error": error_msg})

@app.post("/index_url/")
async def upload_url(url: str = Form(...), source: str = Form(default="web")):
    try:
        logger.info(f"ğŸŒ URL í¬ë¡¤ë§ ìš”ì²­: {url}")

        # âœ… ì›¹ í˜ì´ì§€ ìš”ì²­ ë° íŒŒì‹±
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            return JSONResponse(status_code=400, content={"error": f"Failed to fetch URL: {response.status_code}"})

        soup = BeautifulSoup(response.text, "html.parser")

        # âœ… ì£¼ìš” íƒœê·¸ ìœ„ì£¼ë¡œ í…ìŠ¤íŠ¸ êµ¬ì¡°í™”
        lines = []

        # ì œëª© ê³„ì—´ ë¨¼ì €
        for header in soup.find_all(['h1', 'h2', 'h3', 'h4']):
            lines.append(f"# {header.get_text(strip=True)}")

        # ë‹¨ë½
        for paragraph in soup.find_all('p'):
            lines.append(paragraph.get_text(strip=True))

        # ë¦¬ìŠ¤íŠ¸
        for li in soup.find_all('li'):
            lines.append(f"- {li.get_text(strip=True)}")

        # ê¸°íƒ€ í…ìŠ¤íŠ¸ ëˆ„ë½ ë°©ì§€ìš© (ê¸°ë³¸ì  bodyì—ì„œ ì¶”ê°€ë¡œ ê°€ì ¸ì˜¤ê¸°)
        body_text = soup.body.get_text(separator="\n", strip=True) if soup.body else ""
        lines.append(body_text)

        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        clean_lines = []
        for line in lines:
            line = line.strip()
            if line and line not in clean_lines:
                clean_lines.append(line)

        text = "\n".join(clean_lines)

        # âœ… íŒŒì¼ ì €ì¥
        safe_source = re.sub(r'[\\/]', '_', source.strip()) or "web"
        txt_filename = f"{safe_source}.txt"
        txt_path = os.path.join(DOCS_DIR, txt_filename)
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(text)

        # âœ… ìƒ‰ì¸ ì²˜ë¦¬
        if index_document(txt_path, "txt", force=True):
            return {"message": f"'{url}' í¬ë¡¤ë§ ë° ìƒ‰ì¸ ì„±ê³µ", "source": txt_filename}
        else:
            return JSONResponse(status_code=500, content={"error": "ë¬¸ì„œ ìƒ‰ì¸ ì‹¤íŒ¨"})

    except Exception as e:
        logger.error(f"âŒ upload_url ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

# ask_preview ì—”ë“œí¬ì¸íŠ¸ ì œê±°ë¨

# ==================== ê³µìˆ˜ ì‚°ì • ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.post("/effort/add/")
async def add_effort_estimation(
    jira_ticket: str = Form(...),
    title: str = Form(...),
    story_points: float = Form(...),
    estimation_reason: str = Form(default=None),
    tech_stack: str = Form(default=None),
    team_member: str = Form(default=None),
    notes: str = Form(default=None),
    major_category: str = Form(default=None),
    minor_category: str = Form(default=None),
    sub_category: str = Form(default=None),
    auto_classify: bool = Form(default=False)
):
    """ìˆ˜ë™ìœ¼ë¡œ ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì¶”ê°€ (Story Point ê¸°ë°˜)"""
    try:
        # ê¸°ìˆ  ìŠ¤íƒ íŒŒì‹±
        tech_stack_list = None
        if tech_stack:
            tech_stack_list = [tech.strip() for tech in tech_stack.split(',')]
        
        # ìë™ ë¶„ë¥˜ í™œì„±í™” ì‹œ
        if auto_classify:
            predicted_category, confidence = auto_classify(title)
            if predicted_category and confidence > 0.5:
                logger.info(f"ìë™ ë¶„ë¥˜ ê²°ê³¼: {predicted_category} (ì‹ ë¢°ë„: {confidence:.2f})")
                # ì˜ˆì¸¡ëœ ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¬ìš©
                category_parts = predicted_category.split(' > ')
                if len(category_parts) >= 3:
                    major_category = category_parts[0]
                    minor_category = category_parts[1]
                    sub_category = category_parts[2]
            else:
                logger.warning(f"ìë™ ë¶„ë¥˜ ì‹ ë¢°ë„ ë¶€ì¡±: {confidence:.2f}")
        
        estimation = EffortEstimation(
            jira_ticket=jira_ticket,
            title=title,
            story_points=story_points,
            estimation_reason=estimation_reason,
            tech_stack=tech_stack_list,
            team_member=team_member,
            notes=notes,
            major_category=major_category,
            minor_category=minor_category,
            sub_category=sub_category
        )
        
        if effort_manager.add_estimation(estimation):
            # ê³µìˆ˜ ì‚°ì • ë°ì´í„°ë¥¼ ìƒ‰ì¸ì— ì¶”ê°€
            effort_text = effort_manager.format_for_indexing()
            effort_file_path = os.path.join(DOCS_DIR, "effort_estimations.txt")
            with open(effort_file_path, "w", encoding="utf-8") as f:
                f.write(effort_text)
            
            # ìƒ‰ì¸ ì—…ë°ì´íŠ¸
            index_document(effort_file_path, "txt", force=True)
            
            return {"message": f"ê³µìˆ˜ ì‚°ì • ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {title}"}
        else:
            return JSONResponse(status_code=500, content={"error": "ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨"})
            
    except Exception as e:
        logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

def save_web_qa_mapping(question: str, answer: str, sources: list = None):
    """ì›¹ QA ë§¤í•‘ ì €ì¥"""
    try:
        web_mapping_file = os.path.join(DOCS_DIR, "web_qa_mapping.json")
        
        # ê¸°ì¡´ ë§¤í•‘ ë¡œë“œ
        web_qa_mapping = {}
        if os.path.exists(web_mapping_file):
            try:
                with open(web_mapping_file, 'r', encoding='utf-8') as f:
                    web_qa_mapping = json.load(f)
            except (json.JSONDecodeError, Exception) as e:
                logger.warning(f"âš ï¸ ì›¹ QA ë§¤í•‘ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}, ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì‹œì‘")
                web_qa_mapping = {}
        
        # ìƒˆë¡œìš´ QA í•­ëª© ì¶”ê°€ (íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í‚¤ë¡œ ì‚¬ìš©)
        qa_id = datetime.now().isoformat()
        web_qa_mapping[qa_id] = {
            "question": question,
            "answer": answer,
            "sources": sources or [],
            "timestamp": qa_id,
            "source": "web"
        }
        
        # íŒŒì¼ ì €ì¥
        with open(web_mapping_file, 'w', encoding='utf-8') as f:
            json.dump(web_qa_mapping, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ ì›¹ QA ë§¤í•‘ ì €ì¥: {question[:30]}...")
        return True
    except Exception as e:
        logger.error(f"âŒ ì›¹ QA ë§¤í•‘ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False

@app.post("/effort/ask/")
async def ask_effort_question(question: str = Form(...)):
    """ê³µìˆ˜ ì‚°ì • ê´€ë ¨ ì§ˆë¬¸"""
    try:
        logger.info(f"ğŸ’¬ ê³µìˆ˜ ì‚°ì • ì§ˆë¬¸ ìˆ˜ì‹ : {question}")
        
        try:
            result = run_effort_qa_chain(question)
        except Exception as e:
            if "quota" in str(e).lower() or "insufficient_quota" in str(e).lower():
                logger.warning("âš ï¸ OpenAI API í• ë‹¹ëŸ‰ ì´ˆê³¼, ê³µìˆ˜ ì‚°ì • ëª¨ì˜ ì‘ë‹µ ì‚¬ìš©")
                result = mock_effort_qa_response(question)
            else:
                raise e
        
        if "error" in result:
            return JSONResponse(status_code=400, content={"error": result["error"]})
        
        # ì›¹ QA ë§¤í•‘ ì €ì¥
        save_web_qa_mapping(
            question=result["question"],
            answer=result["answer"],
            sources=result.get("sources", [])
        )
        
        sources_text = format_sources(result["sources"])
        
        return {
            "question": result["question"],
            "answer": result["answer"],
            "formatted_response": f"{result['answer']}{sources_text}",
            "feedback_enabled": result.get("feedback_enabled", False),
            "search_session_id": result.get("search_session_id", ""),
            "sources": result.get("sources", [])
        }
        
    except Exception as e:
        logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/ask-feedback/")
async def ask_effort_question_with_feedback(request: dict):
    """í”¼ë“œë°± ê¸°ë°˜ ê³µìˆ˜ ì‚°ì • ì§ˆë¬¸ ì¬ê²€ìƒ‰"""
    try:
        question = request.get("question", "")
        excluded_sources = request.get("excluded_sources", [])
        
        logger.info(f"ğŸ”„ í”¼ë“œë°± ê¸°ë°˜ ê³µìˆ˜ ì‚°ì • ì§ˆë¬¸ ìˆ˜ì‹ : {question}")
        logger.info(f"ğŸš« ì œì™¸í•  ì†ŒìŠ¤: {excluded_sources}")
        
        try:
            result = run_effort_qa_with_feedback(question, excluded_sources)
        except Exception as e:
            if "quota" in str(e).lower() or "insufficient_quota" in str(e).lower():
                logger.warning("âš ï¸ OpenAI API í• ë‹¹ëŸ‰ ì´ˆê³¼, ê³µìˆ˜ ì‚°ì • ëª¨ì˜ ì‘ë‹µ ì‚¬ìš©")
                result = mock_effort_qa_response(question)
            else:
                raise e
        
        if "error" in result:
            return JSONResponse(status_code=400, content={"error": result["error"]})
        
        sources_text = format_sources(result["sources"])
        
        return {
            "question": result["question"],
            "answer": result["answer"],
            "formatted_response": f"{result['answer']}{sources_text}",
            "feedback_enabled": result.get("feedback_enabled", False),
            "search_session_id": result.get("search_session_id", ""),
            "sources": result.get("sources", []),
            "is_feedback_search": result.get("is_feedback_search", False)
        }
        
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ê¸°ë°˜ ê³µìˆ˜ ì‚°ì • ì§ˆë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/statistics/")
async def get_effort_statistics_endpoint():
    """ê³µìˆ˜ ì‚°ì • í†µê³„ ì¡°íšŒ"""
    try:
        stats = get_effort_statistics()
        return stats
    except Exception as e:
        logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/feedback-statistics/weekly-positive-ratio/")
async def get_feedback_weekly_positive_ratio_endpoint():
    """ì£¼ ë‹¨ìœ„ ê¸ì • í”¼ë“œë°± ë¹„ìœ¨ í†µê³„ ì¡°íšŒ"""
    try:
        from ..services.effort_qa import get_feedback_weekly_positive_ratio
        stats = get_feedback_weekly_positive_ratio()
        return stats
    except Exception as e:
        logger.error(f"âŒ ì£¼ ë‹¨ìœ„ í”¼ë“œë°± í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/search/{feature_name}")
async def search_effort_features(feature_name: str):
    """ê¸°ëŠ¥ëª…ìœ¼ë¡œ ê³µìˆ˜ ì‚°ì • ë°ì´í„° ê²€ìƒ‰"""
    try:
        results = search_similar_features(feature_name)
        return {"feature_name": feature_name, "results": results}
    except Exception as e:
        logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/debug-search/")
async def debug_search_effort_features(query: str):
    """ë””ë²„ê¹…ìš© ê³µìˆ˜ ì‚°ì • ë°ì´í„° ê²€ìƒ‰"""
    try:
        logger.info(f"ğŸ” ë””ë²„ê¹… ê²€ìƒ‰ ìš”ì²­: '{query}'")
        
        # ì§ì ‘ ë°ì´í„° ê²€ìƒ‰
        estimations = effort_manager.get_all_estimations()
        logger.info(f"ğŸ“Š ì „ì²´ ë°ì´í„° ìˆ˜: {len(estimations)}")
        
        # ì œëª©ìœ¼ë¡œ ê²€ìƒ‰
        matching_estimations = []
        for est in estimations:
            if query.lower() in est.title.lower():
                matching_estimations.append({
                    "jira_ticket": est.jira_ticket,
                    "title": est.title,
                    "story_points": est.story_points
                })
        
        logger.info(f"ğŸ” ë§¤ì¹­ëœ ë°ì´í„° ìˆ˜: {len(matching_estimations)}")
        
        return {
            "query": query,
            "total_estimations": len(estimations),
            "matching_estimations": matching_estimations,
            "all_titles": [est.title for est in estimations[:10]]  # ì²˜ìŒ 10ê°œ ì œëª©ë§Œ
        }
    except Exception as e:
        logger.error(f"âŒ ë””ë²„ê¹… ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/vector-status/")
async def get_vector_db_status():
    """ë²¡í„° DB ìƒíƒœ í™•ì¸"""
    try:
        logger.info("ğŸ” ë²¡í„° DB ìƒíƒœ í™•ì¸ ì‹œì‘")
        
        vectordb = get_vectordb()
        collection = vectordb.get()
        
        # ì†ŒìŠ¤ë³„ ë¬¸ì„œ ìˆ˜ ì§‘ê³„
        source_counts = {}
        for metadata in collection["metadatas"]:
            if isinstance(metadata, dict):
                source = metadata.get("source", "unknown")
                source_counts[source] = source_counts.get(source, 0) + 1
        
        logger.info(f"ğŸ“Š ë²¡í„° DB ì „ì²´ ë¬¸ì„œ ìˆ˜: {len(collection['ids'])}")
        logger.info(f"ğŸ“Š ì†ŒìŠ¤ë³„ ë¬¸ì„œ ìˆ˜: {source_counts}")
        
        return {
            "total_documents": len(collection['ids']),
            "source_counts": source_counts,
            "sources": list(source_counts.keys())
        }
    except Exception as e:
        logger.error(f"âŒ ë²¡í„° DB ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/cleanup-temp/")
async def cleanup_temp_files():
    """TEMP.txt íŒŒì¼ ë²¡í„° DBì—ì„œ ì œê±°"""
    try:
        logger.info("ğŸ§¹ TEMP.txt íŒŒì¼ ì •ë¦¬ ì‹œì‘")
        
        vectordb = get_vectordb()
        collection = vectordb.get()
        
        # TEMP.txt ê´€ë ¨ ë¬¸ì„œ ID ì°¾ê¸°
        temp_doc_ids = []
        for i, metadata in enumerate(collection["metadatas"]):
            if isinstance(metadata, dict) and metadata.get("source") == "TEMP.txt":
                temp_doc_ids.append(collection["ids"][i])
        
        if temp_doc_ids:
            # TEMP.txt ë¬¸ì„œë“¤ ì‚­ì œ
            vectordb._collection.delete(temp_doc_ids)
            logger.info(f"ğŸ—‘ï¸ TEMP.txt ë¬¸ì„œ {len(temp_doc_ids)}ê°œ ì‚­ì œ ì™„ë£Œ")
            
            return {
                "message": f"TEMP.txt íŒŒì¼ {len(temp_doc_ids)}ê°œ ë¬¸ì„œê°€ ë²¡í„° DBì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "removed_count": len(temp_doc_ids)
            }
        else:
            return {
                "message": "TEMP.txt íŒŒì¼ì´ ë²¡í„° DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "removed_count": 0
            }
            
    except Exception as e:
        logger.error(f"âŒ TEMP.txt ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/reindex/")
async def reindex_effort_data():
    """ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì¬ì¸ë±ì‹±"""
    try:
        logger.info("ğŸ”„ ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì¬ì¸ë±ì‹± ì‹œì‘")
        
        # effort_estimations.txt íŒŒì¼ ì¬ì¸ë±ì‹±
        effort_file_path = os.path.join(DOCS_DIR, "effort_estimations.txt")
        
        if os.path.exists(effort_file_path):
            logger.info(f"ğŸ“„ effort_estimations.txt íŒŒì¼ ë°œê²¬: {effort_file_path}")
            
            # ê°•ì œ ì¬ì¸ë±ì‹±
            if index_document(effort_file_path, file_type="txt", force=True):
                logger.info("âœ… effort_estimations.txt ì¬ì¸ë±ì‹± ì™„ë£Œ")
                
                # ë²¡í„° DB ìƒíƒœ í™•ì¸
                vectordb = get_vectordb()
                collection = vectordb.get()
                logger.info(f"ğŸ“Š ë²¡í„° DB ë¬¸ì„œ ìˆ˜: {len(collection['ids'])}")
                
                # effort_estimations.txt ê´€ë ¨ ë¬¸ì„œ ìˆ˜ í™•ì¸
                effort_docs = 0
                for metadata in collection["metadatas"]:
                    if isinstance(metadata, dict) and metadata.get("source") == "effort_estimations.txt":
                        effort_docs += 1
                
                logger.info(f"ğŸ“Š effort_estimations.txt ë¬¸ì„œ ìˆ˜: {effort_docs}")
                
                return {
                    "message": "ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì¬ì¸ë±ì‹± ì™„ë£Œ",
                    "total_documents": len(collection['ids']),
                    "effort_documents": effort_docs
                }
            else:
                return JSONResponse(status_code=500, content={"error": "ì¬ì¸ë±ì‹± ì‹¤íŒ¨"})
        else:
            return JSONResponse(status_code=404, content={"error": "effort_estimations.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})
            
    except Exception as e:
        logger.error(f"âŒ ì¬ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/sync-jira/")
async def sync_jira_data(request: Request):
    """Jira í‹°ì¼“ ë°ì´í„° ë™ê¸°í™”"""
    try:
        # ìš”ì²­ ë°ì´í„° ë¡œê¹…
        logger.info(f"ğŸ”„ Jira ë™ê¸°í™” ìš”ì²­ ìˆ˜ì‹  ì‹œì‘")
        
        # Content-Type í™•ì¸
        content_type = request.headers.get("content-type", "")
        logger.info(f"ğŸ”„ Content-Type: {content_type}")
        
        # FormData íŒŒì‹±
        form_data = await request.form()
        logger.info(f"ğŸ”„ FormData keys: {list(form_data.keys())}")
        
        ticket_key = form_data.get("ticket_key")
        major_category = form_data.get("major_category")
        minor_category = form_data.get("minor_category")
        sub_category = form_data.get("sub_category")
        logger.info(f"ğŸ”„ Jira ë™ê¸°í™” ìš”ì²­ ìˆ˜ì‹ : ticket_key={ticket_key}, categories={major_category}/{minor_category}/{sub_category}")
        
        if not ticket_key:
            logger.error("âŒ ticket_key íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return JSONResponse(status_code=422, content={"error": "ticket_key íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"})
        
        jira = create_jira_integration()
        if not jira:
            logger.error("âŒ Jira ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤")
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        if not jira.test_connection():
            logger.error("âŒ Jira ì—°ê²° ì‹¤íŒ¨")
            return JSONResponse(status_code=400, content={"error": "Jira ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"})
        
        logger.info(f"ğŸ”„ í‹°ì¼“ '{ticket_key}' ë™ê¸°í™” ì‹œì‘")
        result = jira.sync_ticket_data(ticket_key, major_category, minor_category, sub_category)
        
        if result["success"]:
            # ìƒ‰ì¸ ì—…ë°ì´íŠ¸
            effort_text = effort_manager.format_for_indexing()
            effort_file_path = os.path.join(DOCS_DIR, "effort_estimations.txt")
            with open(effort_file_path, "w", encoding="utf-8") as f:
                f.write(effort_text)
            
            index_document(effort_file_path, "txt", force=True)
            
            logger.info(f"âœ… í‹°ì¼“ '{ticket_key}' ë™ê¸°í™” ì™„ë£Œ")
            return {"message": f"í‹°ì¼“ '{ticket_key}' ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ"}
        else:
            # í‹°ì¼“ íƒ€ì… í•„í„°ë§ì¸ ê²½ìš° íŠ¹ë³„í•œ ë©”ì‹œì§€ ë°˜í™˜
            if result["reason"] == "not_found_or_invalid_type":
                logger.warning(f"âš ï¸ í—ˆìš©ë˜ì§€ ì•Šì€ í‹°ì¼“ íƒ€ì…: {ticket_key}")
                return JSONResponse(
                    status_code=400, 
                    content={"error": f"Epic íƒ€ì…ì˜ í‹°ì¼“ì€ ë™ê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í—ˆìš©ëœ íƒ€ì…: ì‘ì—…, ìŠ¤í† ë¦¬, ë²„ê·¸, Story, Task, Bug"}
                )
            elif result["reason"] == "no_estimation_data":
                logger.warning(f"âš ï¸ ê³µìˆ˜ ë°ì´í„° ì—†ìŒ: {ticket_key}")
                return JSONResponse(status_code=400, content={"error": f"í‹°ì¼“ '{ticket_key}'ì—ì„œ ê³µìˆ˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})
            else:
                logger.error(f"âŒ í‹°ì¼“ '{ticket_key}' ë™ê¸°í™” ì‹¤íŒ¨")
                return JSONResponse(status_code=500, content={"error": "Jira ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨"})
            
    except Exception as e:
        logger.error(f"âŒ Jira ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/list/")
async def list_effort_estimations(
    major_category: str = None,
    minor_category: str = None,
    sub_category: str = None,
    search: str = None,
    page: int = 1,
    page_size: int = 100
):
    """ê³µìˆ˜ ì‚°ì • ë°ì´í„° ëª©ë¡ ì¡°íšŒ (ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì§€ì›)"""
    try:
        estimations = effort_manager.get_all_estimations()
        
        # ê²€ìƒ‰ ì ìš© (ì œëª© ë˜ëŠ” Jira í‹°ì¼“)
        if search:
            search_term = search.lower().strip()
            filtered_estimations = []
            for estimation in estimations:
                # ì œëª©ì—ì„œ ê²€ìƒ‰
                if search_term in estimation.title.lower():
                    filtered_estimations.append(estimation)
                # Jira í‹°ì¼“ì—ì„œ ê²€ìƒ‰
                elif estimation.jira_ticket and search_term in estimation.jira_ticket.lower():
                    filtered_estimations.append(estimation)
            estimations = filtered_estimations
        
        # í˜ì´ì§• ì²˜ë¦¬
        total_count = len(estimations)
        total_pages = (total_count + page_size - 1) // page_size  # ì˜¬ë¦¼ ê³„ì‚°
        
        # í˜ì´ì§€ ë²”ìœ„ ê³„ì‚°
        start_index = (page - 1) * page_size
        end_index = start_index + page_size
        
        # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ
        paginated_estimations = estimations[start_index:end_index]
        
        # ë„˜ë²„ë§ ì¶”ê°€ (ì „ì²´ ë°ì´í„° ê¸°ì¤€)
        for i, estimation in enumerate(paginated_estimations):
            estimation.sequence_number = start_index + i + 1
        
        # ë°ì´í„° ëª©ë¡ìš©: descriptionê³¼ comments ì œì™¸ (ì‘ë‹µ í¬ê¸° ì¶•ì†Œ)
        estimations_data = []
        for estimation in paginated_estimations:
            est_dict = estimation.__dict__.copy()
            # descriptionê³¼ comments ì œì™¸ (ê¸´ í…ìŠ¤íŠ¸)
            est_dict.pop('description', None)
            est_dict.pop('comments', None)
            estimations_data.append(est_dict)
        
        jira_url = os.getenv('JIRA_URL', 'https://enomix.atlassian.net')
        return {
            "estimations": estimations_data,
            "jira_url": jira_url,
            "pagination": {
                "current_page": page,
                "page_size": page_size,
                "total_count": total_count,
                "total_pages": total_pages,
                "has_previous": page > 1,
                "has_next": page < total_pages
            }
        }
    except Exception as e:
        logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

# ì¹´í…Œê³ ë¦¬ ê´€ë¦¬ API
@app.post("/effort/auto-classify/")
async def auto_classify_estimations():
    """ë¯¸ë¶„ë¥˜ ë°ì´í„° ìë™ ë¶„ë¥˜"""
    try:
        estimations = effort_manager.get_all_estimations()
        
        # ë¯¸ë¶„ë¥˜ ë°ì´í„° í•„í„°ë§ (ì¹´í…Œê³ ë¦¬ê°€ ì—†ëŠ” ê²½ìš°)
        unclassified = [
            est for est in estimations 
            if not est.major_category or not est.minor_category or not est.sub_category
        ]
        
        logger.info(f"ë¯¸ë¶„ë¥˜ ë°ì´í„°: {len(unclassified)}ê°œ")
        
        # ìë™ ë¶„ë¥˜ ì‹¤í–‰
        classified_count = 0
        total_confidence = 0
        
        # ì‹ ë¢°ë„ë³„ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        low_confidence = []  # 0.1 ~ 0.3
        medium_confidence = []  # 0.3 ~ 0.5
        high_confidence = []  # 0.5 ì´ìƒ
        
        for estimation in unclassified:
            # ì œëª©ê³¼ ì„¤ëª…ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜
            classification_text = estimation.title
            if estimation.notes:
                classification_text += " " + estimation.notes
            
            predicted_category, confidence = auto_classify(classification_text)
            
            # confidenceë¥¼ ëª…ì‹œì ìœ¼ë¡œ floatë¡œ ë³€í™˜
            try:
                conf_float = float(confidence) if confidence is not None else 0.0
                conf_str = f"{conf_float:.2f}"
            except Exception as e:
                logger.error(f"âŒ confidence ë³€í™˜ ì˜¤ë¥˜: {e}, confidence={confidence}, type={type(confidence)}")
                conf_float = 0.0
                conf_str = "0.00"
            
            if predicted_category and conf_float >= 0.5:
                # ë†’ì€ ì‹ ë¢°ë„: ìë™ ì ìš©
                category_parts = predicted_category.split(' > ')
                if len(category_parts) >= 3:
                    estimation.major_category = category_parts[0]
                    estimation.minor_category = category_parts[1]
                    estimation.sub_category = category_parts[2]
                    classified_count += 1
                    total_confidence += conf_float
                    high_confidence.append((estimation.title, predicted_category, conf_float))
                    logger.info(f"âœ… ìë™ ë¶„ë¥˜ (ë†’ìŒ): {estimation.title} -> {predicted_category} (ì‹ ë¢°ë„: {conf_str})")
            elif predicted_category and conf_float >= 0.3:
                # ì¤‘ê°„ ì‹ ë¢°ë„: ì‚¬ìš©ì í™•ì¸ í›„ ì ìš©
                medium_confidence.append((estimation.title, predicted_category, conf_float))
                logger.info(f"âš ï¸ ì‹ ë¢°ë„ ì¤‘ê°„: {estimation.title} -> {predicted_category} (ì‹ ë¢°ë„: {conf_str})")
            elif predicted_category and conf_float >= 0.1:
                # ë‚®ì€ ì‹ ë¢°ë„: ì œì•ˆë§Œ
                low_confidence.append((estimation.title, predicted_category, conf_float))
                logger.info(f"ğŸ“ ì‹ ë¢°ë„ ë‚®ìŒ: {estimation.title} -> {predicted_category} (ì‹ ë¢°ë„: {conf_str})")
            else:
                logger.info(f"âŒ ë¶„ë¥˜ ì‹¤íŒ¨: {estimation.title} (ì‹ ë¢°ë„: {conf_str if conf_float else 'N/A'})")
        
        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = total_confidence / classified_count if classified_count > 0 else 0
        
        # ë³€ê²½ì‚¬í•­ ì €ì¥
        effort_manager.save_data()
        
        # íŠœí”Œì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
        def tuple_to_dict(tup_list):
            return [
                {
                    "title": str(tup[0]),
                    "category": str(tup[1]),
                    "confidence": round(float(tup[2]), 2)
                }
                for tup in tup_list
            ]
        
        return {
            "message": "ìë™ ë¶„ë¥˜ ì™„ë£Œ",
            "total_unclassified": len(unclassified),
            "high_confidence_count": len(high_confidence),
            "medium_confidence_count": len(medium_confidence),
            "low_confidence_count": len(low_confidence),
            "classified_count": classified_count,
            "average_confidence": round(avg_confidence, 2),
            "high_confidence": tuple_to_dict(high_confidence[:5]),
            "medium_confidence": tuple_to_dict(medium_confidence[:5]),
            "low_confidence": tuple_to_dict(low_confidence[:5])
        }
        
    except Exception as e:
        logger.error(f"âŒ ìë™ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/categories/")
async def get_categories():
    """ì¹´í…Œê³ ë¦¬ êµ¬ì¡° ì¡°íšŒ"""
    try:
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        return category_manager.get_categories()
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/categories/major/")
async def get_major_categories():
    """ëŒ€ë¶„ë¥˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        return {"categories": category_manager.get_major_categories()}
    except Exception as e:
        logger.error(f"âŒ ëŒ€ë¶„ë¥˜ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/categories/minor/")
async def get_minor_categories(major: str):
    """ì¤‘ë¶„ë¥˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        return {"categories": category_manager.get_minor_categories(major)}
    except Exception as e:
        logger.error(f"âŒ ì¤‘ë¶„ë¥˜ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/effort/categories/sub/")
async def get_sub_categories(major: str, minor: str):
    """ì†Œë¶„ë¥˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        return {"categories": category_manager.get_sub_categories(major, minor)}
    except Exception as e:
        logger.error(f"âŒ ì†Œë¶„ë¥˜ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/categories/")
async def add_category(request: Request):
    """ìƒˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€"""
    try:
        data = await request.json()
        major = data.get("major")
        minor = data.get("minor")
        sub = data.get("sub")
        
        if not all([major, minor, sub]):
            return JSONResponse(status_code=400, content={"error": "ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜, ì†Œë¶„ë¥˜ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤"})
        
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        category_manager.add_category(major, minor, sub)
        
        return {"message": "ì¹´í…Œê³ ë¦¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.put("/effort/categories/")
async def update_category(request: Request):
    """ì¹´í…Œê³ ë¦¬ ìˆ˜ì •"""
    try:
        data = await request.json()
        old_major = data.get("old_major")
        old_minor = data.get("old_minor")
        old_sub = data.get("old_sub")
        new_major = data.get("new_major")
        new_minor = data.get("new_minor")
        new_sub = data.get("new_sub")
        
        if not all([old_major, old_minor, old_sub, new_major, new_minor, new_sub]):
            return JSONResponse(status_code=400, content={"error": "ëª¨ë“  í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"})
        
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        category_manager.update_category(old_major, old_minor, old_sub, new_major, new_minor, new_sub)
        
        return {"message": "ì¹´í…Œê³ ë¦¬ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ìˆ˜ì • ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.delete("/effort/categories/")
async def delete_category(request: Request):
    """ì¹´í…Œê³ ë¦¬ ì‚­ì œ"""
    try:
        data = await request.json()
        major = data.get("major")
        minor = data.get("minor")
        sub = data.get("sub")
        
        if not all([major, minor, sub]):
            return JSONResponse(status_code=400, content={"error": "ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜, ì†Œë¶„ë¥˜ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤"})
        
        from ..services.effort_estimation import CategoryManager
        category_manager = CategoryManager()
        category_manager.delete_category(major, minor, sub)
        
        return {"message": "ì¹´í…Œê³ ë¦¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.put("/effort/update-category/")
async def update_effort_category(request: Request):
    """ê³µìˆ˜ ì‚°ì • ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ ìˆ˜ì •"""
    try:
        data = await request.json()
        jira_ticket = data.get("jira_ticket")
        major_category = data.get("major_category")
        minor_category = data.get("minor_category")
        sub_category = data.get("sub_category")
        
        if not all([jira_ticket, major_category, minor_category, sub_category]):
            return JSONResponse(status_code=400, content={"error": "ëª¨ë“  í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"})
        
        from ..services.effort_estimation import effort_manager
        success = effort_manager.update_estimation_category(jira_ticket, major_category, minor_category, sub_category)
        
        if success:
            return {"message": "ì¹´í…Œê³ ë¦¬ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤"}
        else:
            return JSONResponse(status_code=404, content={"error": "í•´ë‹¹ í‹°ì¼“ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ìˆ˜ì • ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.delete("/effort/delete/{jira_ticket}")
async def delete_effort_estimation(jira_ticket: str):
    """ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì‚­ì œ (ë¹„í™œì„±í™”ë¨ - ë°ì´í„° ë³´í˜¸)"""
    # ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ ì‚­ì œ ê¸°ëŠ¥ ë¹„í™œì„±í™”
    logger.warning(f"âš ï¸ ì‚­ì œ ì‹œë„ ì°¨ë‹¨: {jira_ticket} (ì‚­ì œ ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨)")
    return JSONResponse(
        status_code=403, 
        content={
            "error": "ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ ì‚­ì œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤",
            "message": "ì˜ëª»ëœ ë°ì´í„°ëŠ” ìˆ˜ì • ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”"
        }
    )
    
    # ì›ë³¸ ì½”ë“œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
    # try:
    #     from ..services.effort_estimation import effort_manager
    #     
    #     # í•´ë‹¹ í‹°ì¼“ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    #     estimation = effort_manager.get_estimation_by_ticket(jira_ticket)
    #     if not estimation:
    #         return JSONResponse(status_code=404, content={"error": "í•´ë‹¹ í‹°ì¼“ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})
    #     
    #     # ì‚­ì œ ì‹¤í–‰
    #     success = effort_manager.delete_estimation(jira_ticket)
    #     
    #     if success:
    #         logger.info(f"âœ… ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {jira_ticket}")
    #         return {"message": "ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
    #     else:
    #         logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {jira_ticket}")
    #         return JSONResponse(status_code=500, content={"error": "ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"})
    # except Exception as e:
    #     logger.error(f"âŒ ê³µìˆ˜ ì‚°ì • ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
    #     return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/sync-epic/")
async def sync_epic_data(request: Request):
    """Epic í•˜ìœ„ ì‘ì—… ë™ê¸°í™”"""
    try:
        # ìš”ì²­ ë°ì´í„° ë¡œê¹…
        logger.info(f"ğŸ”„ Epic ë™ê¸°í™” ìš”ì²­ ìˆ˜ì‹  ì‹œì‘")
        
        # ë™ê¸°í™” ì „ ë°ì´í„° ë°±ì—…
        from ..services.effort_estimation import effort_manager
        logger.info("ğŸ’¾ ë™ê¸°í™” ì‹œì‘ ì „ ë°ì´í„° ë°±ì—… ì¤‘...")
        effort_manager.backup_data()
        
        # Content-Type í™•ì¸
        content_type = request.headers.get("content-type", "")
        logger.info(f"ğŸ”„ Content-Type: {content_type}")
        
        # FormData íŒŒì‹±
        form_data = await request.form()
        logger.info(f"ğŸ”„ FormData keys: {list(form_data.keys())}")
        
        epic_key = form_data.get("epic_key")
        major_category = form_data.get("major_category")
        minor_category = form_data.get("minor_category")
        sub_category = form_data.get("sub_category")
        title_filter = form_data.get("title_filter", "").strip()
        logger.info(f"ğŸ”„ Epic ë™ê¸°í™” ìš”ì²­ ìˆ˜ì‹ : epic_key={epic_key}, categories={major_category}/{minor_category}/{sub_category}, title_filter={title_filter}")
        
        if not epic_key:
            logger.error("âŒ epic_key íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return JSONResponse(status_code=422, content={"error": "epic_key íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"})
        
        jira = create_jira_integration()
        if not jira:
            logger.error("âŒ Jira ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤")
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        # Epic ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (Epic ì´ë¦„ ê°€ì ¸ì˜¤ê¸°)
        epic_info = jira.test_epic_basic_info(epic_key)
        epic_name = "ì•Œ ìˆ˜ ì—†ìŒ"
        if epic_info and isinstance(epic_info, dict):
            fields = epic_info.get('fields', {})
            epic_name = fields.get('summary', epic_key) if fields else epic_key
        logger.info(f"ğŸ”„ Epic ì •ë³´: {epic_key} - {epic_name}")
        
        # Epic í•˜ìœ„ ì‘ì—… ì¡°íšŒ
        subtasks_result = jira.test_epic_subtasks(epic_key)
        if not subtasks_result or not subtasks_result.get("success"):
            error_msg = subtasks_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜") if subtasks_result else "Epic ì¡°íšŒ ì‹¤íŒ¨"
            logger.error(f"âŒ Epic í•˜ìœ„ ì‘ì—… ì¡°íšŒ ì‹¤íŒ¨: {epic_key} - {error_msg}")
            return JSONResponse(status_code=404, content={"error": f"Epic '{epic_key}'ì˜ í•˜ìœ„ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {error_msg}"})
        
        # ì‘ì—… íƒ€ì… í•„í„°ë§ (Epicë§Œ ì œì™¸í•˜ê³  ëª¨ë“  íƒ€ì… í—ˆìš©)
        tasks = subtasks_result.get("subtasks", [])
        excluded_types = ['Epic', 'ì—í”½']  # Epic ìì²´ë§Œ ì œì™¸
        filtered_tasks = [task for task in tasks if task.get("issue_type") not in excluded_types]
        
        logger.info(f"ğŸ”„ ì‘ì—… íƒ€ì… í•„í„°ë§: ì´ {len(tasks)}ê°œ â†’ {len(filtered_tasks)}ê°œ")
        logger.info(f"ğŸ”„ ì‹¤ì œ íƒ€ì…ë“¤: {[task.get('issue_type') for task in tasks[:10]]}")  # ì²˜ìŒ 10ê°œë§Œ ë¡œê¹…
        logger.info(f"ğŸ”„ ì œì™¸ëœ íƒ€ì…: {excluded_types}")
        
        # ì œëª© í•„í„°ë§ (ì„ íƒì‚¬í•­)
        if title_filter:
            original_count = len(filtered_tasks)
            filtered_tasks = [task for task in filtered_tasks if title_filter.lower() in task.get("summary", "").lower()]
            logger.info(f"ğŸ”„ ì œëª© í•„í„°ë§: '{title_filter}' - {original_count}ê°œ â†’ {len(filtered_tasks)}ê°œ")
        
        logger.info(f"ğŸ”„ Epic '{epic_key}' í•˜ìœ„ ì‘ì—…: ì´ {len(tasks)}ê°œ, í•„í„°ë§ í›„ {len(filtered_tasks)}ê°œ")
        
        if not filtered_tasks:
            return JSONResponse(status_code=404, content={"error": f"Epic '{epic_key}'ì— í•˜ìœ„ ì‘ì—…ì´ ì—†ê±°ë‚˜ ëª¨ë‘ Epic íƒ€ì…ì…ë‹ˆë‹¤"})
        
        # ê° ì‘ì—…ì„ ê³µìˆ˜ ì‚°ì • ë°ì´í„°ë¡œ ë³€í™˜
        from ..services.effort_estimation import effort_manager
        
        added_count = 0
        updated_count = 0
        skipped_count = 0
        
        for task in filtered_tasks:
            try:
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                existing = effort_manager.get_estimation_by_ticket(task["key"])
                
                if existing:
                    # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ (ì¹´í…Œê³ ë¦¬)
                    effort_manager.update_estimation_category(
                        task["key"], 
                        major_category or existing.major_category or "",
                        minor_category or existing.minor_category or "",
                        sub_category or existing.sub_category or ""
                    )
                    # Epic ì •ë³´ ì—…ë°ì´íŠ¸
                    effort_manager.update_estimation_epic(
                        task["key"],
                        epic_key,
                        epic_name
                    )
                    updated_count += 1
                    logger.info(f"âœ… ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸: {task['key']} (Epic: {epic_key})")
                else:
                    # ìƒˆ ë°ì´í„° ì¶”ê°€ (description í¬í•¨, commentsë§Œ ì œì™¸)
                    from ..services.effort_estimation import EffortEstimation
                    
                    new_estimation = EffortEstimation(
                        jira_ticket=task["key"],
                        title=task["summary"],
                        story_points=task.get("story_points", 0),
                        description=task.get("description", None),  # description í¬í•¨
                        comments=None,  # commentsë§Œ ì œì™¸
                        team_member=task.get("assignee", ""),
                        estimation_reason="Epic í•˜ìœ„ ì‘ì—… ìë™ ë™ê¸°í™”",
                        major_category=major_category or "",
                        minor_category=minor_category or "",
                        sub_category=sub_category or "",
                        epic_key=epic_key,
                        epic_name=epic_name,
                        story_points_original=task.get("story_points_original"),
                        story_points_unit=task.get("story_points_unit", "M/D")
                    )
                    
                    effort_manager.add_estimation(new_estimation)
                    added_count += 1
                    logger.info(f"âœ… ìƒˆ ë°ì´í„° ì¶”ê°€: {task['key']} (Epic: {epic_key})")
                    
            except Exception as e:
                logger.error(f"âŒ ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨ {task['key']}: {str(e)}")
                skipped_count += 1
        
        # Epic ë™ê¸°í™” ì™„ë£Œ í›„ ì¦ë¶„ ìƒ‰ì¸ì€ ë³„ë„ ë°°ì¹˜ë¡œ ì‹¤í–‰ (ì†ë„ ê°œì„ )
        # if added_count > 0 or updated_count > 0:
        #     logger.info("ğŸ”„ Epic ë™ê¸°í™” í›„ ì¦ë¶„ ìƒ‰ì¸ ì‹œì‘")
        #     try:
        #         # ì¶”ê°€/ìˆ˜ì •ëœ í‹°ì¼“ ëª©ë¡ ìˆ˜ì§‘
        #         synced_tickets = [task["key"] for task in filtered_tasks]
        #         
        #         if synced_tickets:
        #             json_file_path = os.path.join(DOCS_DIR, "effort_estimations.json")
        #             index_json_data_incremental(synced_tickets, json_file_path)
        #             logger.info(f"âœ… Epic ë™ê¸°í™” í›„ ì¦ë¶„ ìƒ‰ì¸ ì™„ë£Œ: {len(synced_tickets)}ê°œ í‹°ì¼“")
        #     except Exception as reindex_error:
        #         logger.warning(f"âš ï¸ Epic ë™ê¸°í™” í›„ ì¦ë¶„ ìƒ‰ì¸ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {str(reindex_error)}")
        
        result = {
            "success": True,
            "epic_key": epic_key,
            "total_tasks": len(filtered_tasks),
            "added_tasks": added_count,
            "updated_tasks": updated_count,
            "skipped_tasks": skipped_count,
            "jql_used": subtasks_result.get("jql_used", "ì•Œ ìˆ˜ ì—†ìŒ"),
            "message": f"Epic '{epic_key}' í•˜ìœ„ ì‘ì—… ë™ê¸°í™” ì™„ë£Œ (ìƒ‰ì¸ì€ 'ë°ì´í„° ì¬ìƒ‰ì¸' ë²„íŠ¼ìœ¼ë¡œ ë³„ë„ ì‹¤í–‰)"
        }
        
        logger.info(f"âœ… Epic ë™ê¸°í™” ì™„ë£Œ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Epic ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

def save_scheduler_history(scheduler_name: str, status: str, details: dict, start_time=None, end_time=None):
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì´ë ¥ ì €ì¥ (ì„±ê³µ/ì‹¤íŒ¨ë§Œ ê¸°ë¡, ì‹¤í–‰ì¤‘ì€ ì œì™¸)"""
    try:
        # "running" ìƒíƒœëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ
        if status == "running":
            return
        
        history_file = os.path.join(DOCS_DIR, "scheduler_history.json")
        
        # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
        history = []
        if os.path.exists(history_file):
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        
        # ìƒˆ ì´ë ¥ ì¶”ê°€
        history.append({
            "scheduler_name": scheduler_name,
            "status": status,  # "success" or "failed"
            "start_time": start_time.isoformat() if start_time else datetime.now().isoformat(),
            "end_time": end_time.isoformat() if end_time else datetime.now().isoformat(),
            "details": details
        })
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        history = history[-100:]
        
        # ì €ì¥
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë ¥ ì €ì¥: {scheduler_name} - {status}")
        
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {str(e)}")

def sync_completed_epics_background():
    """ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (ENOMIX í”„ë¡œì íŠ¸ë§Œ)"""
    global sync_status
    
    start_time = datetime.now()
    
    try:
        logger.info(f"ğŸ”„ ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ (ENOMIX í”„ë¡œì íŠ¸)")
        
        # ë™ê¸°í™” ì „ ë°ì´í„° ë°±ì—…
        from ..services.effort_estimation import effort_manager
        logger.info("ğŸ’¾ ë™ê¸°í™” ì‹œì‘ ì „ ë°ì´í„° ë°±ì—… ì¤‘...")
        effort_manager.backup_data()
        
        # ìƒíƒœ ì´ˆê¸°í™”
        sync_status["is_running"] = True
        sync_status["progress"] = 0
        sync_status["completed_epics"] = 0
        sync_status["failed_epics"] = 0
        sync_status["current_epic"] = ""
        sync_status["message"] = f"Jiraì—ì„œ ì™„ë£Œëœ Epic ê²€ìƒ‰ ì¤‘ (ENOMIX í”„ë¡œì íŠ¸)..."
        sync_status["failed_list"] = []
        
        jira = create_jira_integration()
        if not jira:
            sync_status["is_running"] = False
            sync_status["message"] = "Jira ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤"
            logger.error("âŒ Jira ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ENOMIXëŠ” ê¸°ë³¸ í•„ë“œë§Œ (ë¹ ë¦„)
        include_details = False
        
        # 1. ì™„ë£Œëœ Epic ëª©ë¡ ì¡°íšŒ (ENOMIXë§Œ)
        completed_epics = jira.search_completed_epics()
        
        if not completed_epics:
            sync_status["is_running"] = False
            sync_status["message"] = "ì™„ë£Œëœ Epicì´ ì—†ìŠµë‹ˆë‹¤"
            sync_status["progress"] = 100
            logger.info("â„¹ï¸ ì™„ë£Œëœ Epicì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        sync_status["total_epics"] = len(completed_epics)
        sync_status["message"] = f"{len(completed_epics)}ê°œ Epic ë™ê¸°í™” ì‹œì‘"
        logger.info(f"ğŸ” ì™„ë£Œëœ Epic {len(completed_epics)}ê°œ ë°œê²¬")
        
        # 2. ê° Epic ë™ê¸°í™”
        for idx, epic in enumerate(completed_epics, 1):
            epic_key = epic['key']
            
            try:
                sync_status["current_epic"] = f"{epic_key} - {epic['summary'][:30]}..."
                sync_status["message"] = f"ë™ê¸°í™” ì¤‘: {epic_key} ({idx}/{len(completed_epics)})"
                logger.info(f"ğŸ”„ Epic ë™ê¸°í™” ì¤‘: {epic_key} - {epic['summary'][:50]}...")
                
                # Epic ì •ë³´ ì¡°íšŒ
                epic_info = jira.test_epic_basic_info(epic_key)
                epic_name = "ì•Œ ìˆ˜ ì—†ìŒ"
                if epic_info and isinstance(epic_info, dict):
                    fields = epic_info.get('fields', {})
                    epic_name = fields.get('summary', epic_key) if fields else epic_key
                
                # Epic í•˜ìœ„ ì‘ì—… ì¡°íšŒ (í”„ë¡œì íŠ¸ë³„ë¡œ ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€ ê²°ì •)
                subtasks_result = jira.test_epic_subtasks(epic_key, include_details=include_details)
                if not subtasks_result or not subtasks_result.get("success"):
                    logger.warning(f"âš ï¸ Epic {epic_key} í•˜ìœ„ ì‘ì—… ì—†ìŒ")
                    sync_status["failed_epics"] += 1
                    sync_status["failed_list"].append(f"{epic_key} (í•˜ìœ„ ì‘ì—… ì—†ìŒ)")
                    continue
                
                # ì‘ì—… íƒ€ì… í•„í„°ë§ (Epicë§Œ ì œì™¸í•˜ê³  ëª¨ë“  íƒ€ì… í—ˆìš©)
                tasks = subtasks_result.get("subtasks", [])
                excluded_types = ['Epic', 'ì—í”½']  # Epic ìì²´ë§Œ ì œì™¸
                filtered_tasks = [task for task in tasks if task.get("issue_type") not in excluded_types]
                
                if not filtered_tasks:
                    logger.warning(f"âš ï¸ Epic {epic_key} í•˜ìœ„ ì‘ì—… ì—†ìŒ (Epic íƒ€ì…ë§Œ ìˆìŒ)")
                    sync_status["failed_epics"] += 1
                    sync_status["failed_list"].append(f"{epic_key} (í•˜ìœ„ ì‘ì—… ì—†ìŒ)")
                    continue
                
                # ê° ì‘ì—…ì„ ê³µìˆ˜ ì‚°ì • ë°ì´í„°ë¡œ ë³€í™˜
                from ..services.effort_estimation import effort_manager, EffortEstimation
                
                task_added = 0
                task_updated = 0
                
                for task in filtered_tasks:
                    try:
                        existing = effort_manager.get_estimation_by_ticket(task["key"])
                        
                        if existing:
                            # ê¸°ì¡´ ë°ì´í„° Epic ì •ë³´ ì—…ë°ì´íŠ¸
                            effort_manager.update_estimation_epic(task["key"], epic_key, epic_name)
                            task_updated += 1
                        else:
                            # ìƒˆ ë°ì´í„° ì¶”ê°€ (description í¬í•¨, commentsë§Œ ì œì™¸)
                            new_estimation = EffortEstimation(
                                jira_ticket=task["key"],
                                title=task["summary"],
                                story_points=task.get("story_points", 0),
                                description=task.get("description", None),  # description í¬í•¨
                                comments=None,  # commentsë§Œ ì œì™¸
                                team_member=task.get("assignee", ""),
                                estimation_reason="ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™”",
                                major_category="",
                                minor_category="",
                                sub_category="",
                                epic_key=epic_key,
                                epic_name=epic_name,
                                story_points_original=task.get("story_points_original"),
                                story_points_unit=task.get("story_points_unit", "M/D")
                            )
                            effort_manager.add_estimation(new_estimation)
                            task_added += 1
                            
                    except Exception as task_error:
                        logger.error(f"âŒ Task {task['key']} ì²˜ë¦¬ ì‹¤íŒ¨: {str(task_error)}")
                        continue
                
                logger.info(f"âœ… Epic {epic_key} ë™ê¸°í™” ì™„ë£Œ: {task_added}ê°œ ì¶”ê°€, {task_updated}ê°œ ì—…ë°ì´íŠ¸")
                
                # ì¦ë¶„ ìƒ‰ì¸ì€ ë³„ë„ ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰ (ì†ë„ ê°œì„ )
                # if task_added > 0 or task_updated > 0:
                #     try:
                #         synced_tickets = [task["key"] for task in filtered_tasks]
                #         json_file_path = os.path.join(DOCS_DIR, "effort_estimations.json")
                #         index_json_data_incremental(synced_tickets, json_file_path)
                #         logger.info(f"   âœ… ì¦ë¶„ ìƒ‰ì¸ ì™„ë£Œ: {len(synced_tickets)}ê°œ í‹°ì¼“")
                #     except Exception as index_error:
                #         logger.warning(f"   âš ï¸ ì¦ë¶„ ìƒ‰ì¸ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì†): {str(index_error)}")
                
                sync_status["completed_epics"] += 1
                
            except Exception as epic_error:
                logger.error(f"âŒ Epic {epic_key} ë™ê¸°í™” ì‹¤íŒ¨: {str(epic_error)}")
                sync_status["failed_epics"] += 1
                sync_status["failed_list"].append(f"{epic_key} ({str(epic_error)})")
                continue
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            sync_status["progress"] = int((idx / len(completed_epics)) * 100)
        
        # ì™„ë£Œ - ìƒ‰ì¸ì€ ë³„ë„ ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ ì‹¤í–‰
        sync_status["is_running"] = False
        sync_status["progress"] = 100
        sync_status["current_epic"] = ""
        sync_status["message"] = f"ë™ê¸°í™” ì™„ë£Œ: {sync_status['completed_epics']}ê°œ ì„±ê³µ, {sync_status['failed_epics']}ê°œ ì‹¤íŒ¨ (ìƒ‰ì¸ì€ ë³„ë„ ì‹¤í–‰ í•„ìš”)"
        logger.info(f"âœ… ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™” ì™„ë£Œ: {sync_status['message']}")
        logger.info(f"ğŸ’¡ ë²¡í„° DB ìƒ‰ì¸ì€ 'ë°ì´í„° ì¬ìƒ‰ì¸' ë²„íŠ¼ìœ¼ë¡œ ë³„ë„ ì‹¤í–‰í•˜ì„¸ìš”")
        
        # ì„±ê³µ ì´ë ¥ ì €ì¥
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        save_scheduler_history(
            "Epic ìë™ ë™ê¸°í™”",
            "success",
            {
                "total_epics": sync_status["total_epics"],
                "completed_epics": sync_status["completed_epics"],
                "failed_epics": sync_status["failed_epics"],
                "failed_list": sync_status["failed_list"],
                "duration_seconds": duration,
                "message": sync_status["message"]
            },
            start_time=start_time,
            end_time=end_time
        )
        
    except Exception as e:
        logger.error(f"âŒ ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™” ì˜¤ë¥˜: {str(e)}")
        sync_status["is_running"] = False
        sync_status["message"] = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
        # ì‹¤íŒ¨ ì´ë ¥ ì €ì¥
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        save_scheduler_history(
            "Epic ìë™ ë™ê¸°í™”",
            "failed",
            {
                "error": str(e),
                "duration_seconds": duration,
                "message": sync_status["message"]
            },
            start_time=start_time,
            end_time=end_time
        )

@app.post("/effort/auto-sync-completed-epics/")
async def auto_sync_completed_epics(background_tasks: BackgroundTasks):
    """ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™” ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ, ENOMIX í”„ë¡œì íŠ¸ë§Œ)"""
    global sync_status
    
    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    if sync_status["is_running"]:
        return {
            "success": False,
            "message": "ì´ë¯¸ ë™ê¸°í™”ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤",
            "is_running": True
        }
    
    # Jira ì„¤ì • í™•ì¸
    jira = create_jira_integration()
    if not jira:
        return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
    
    logger.info(f"ğŸ”„ ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™” ì‹œì‘: ENOMIX í”„ë¡œì íŠ¸")
    
    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
    background_tasks.add_task(sync_completed_epics_background)
    
    return {
        "success": True,
        "message": "ì™„ë£Œëœ Epic ìë™ ë™ê¸°í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ (ENOMIX). ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.",
        "is_running": True
    }

@app.get("/effort/sync-status/")
async def get_sync_status():
    """ë™ê¸°í™” ìƒíƒœ ì¡°íšŒ"""
    return sync_status

@app.get("/effort/scheduler-history/")
async def get_scheduler_history():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ"""
    try:
        history_file = os.path.join(DOCS_DIR, "scheduler_history.json")
        
        if not os.path.exists(history_file):
            return {
                "success": True,
                "history": [],
                "message": "ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤"
            }
        
        with open(history_file, 'r', encoding='utf-8') as f:
            history = json.load(f)
        
        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
        history.reverse()
        
        return {
            "success": True,
            "history": history,
            "total": len(history)
        }
        
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë ¥ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

# ==================== í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/prompts/intent/stats/")
async def get_intent_prompt_stats():
    """ì˜ë„ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ í†µê³„ ì¡°íšŒ"""
    try:
        stats = intent_prompt_manager.get_stats()
        return stats
    except Exception as e:
        logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/prompts/intent/related/")
async def add_related_example(example: str = Form(...)):
    """ê´€ë ¨ ì˜ˆì‹œ ì¶”ê°€"""
    try:
        success = intent_prompt_manager.add_related_example(example)
        if success:
            return {"message": f"ê´€ë ¨ ì˜ˆì‹œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {example}"}
        else:
            return {"message": f"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤: {example}"}
    except Exception as e:
        logger.error(f"âŒ ê´€ë ¨ ì˜ˆì‹œ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/prompts/intent/unrelated/")
async def add_unrelated_example(example: str = Form(...)):
    """ê´€ë ¨ ì—†ëŠ” ì˜ˆì‹œ ì¶”ê°€"""
    try:
        success = intent_prompt_manager.add_unrelated_example(example)
        if success:
            return {"message": f"ê´€ë ¨ ì—†ëŠ” ì˜ˆì‹œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {example}"}
        else:
            return {"message": f"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤: {example}"}
    except Exception as e:
        logger.error(f"âŒ ê´€ë ¨ ì—†ëŠ” ì˜ˆì‹œ ì¶”ê°€ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.delete("/prompts/intent/related/")
async def remove_related_example(example: str = Form(...)):
    """ê´€ë ¨ ì˜ˆì‹œ ì œê±°"""
    try:
        success = intent_prompt_manager.remove_related_example(example)
        if success:
            return {"message": f"ê´€ë ¨ ì˜ˆì‹œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤: {example}"}
        else:
            return {"message": f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤: {example}"}
    except Exception as e:
        logger.error(f"âŒ ê´€ë ¨ ì˜ˆì‹œ ì œê±° ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.delete("/prompts/intent/unrelated/")
async def remove_unrelated_example(example: str = Form(...)):
    """ê´€ë ¨ ì—†ëŠ” ì˜ˆì‹œ ì œê±°"""
    try:
        success = intent_prompt_manager.remove_unrelated_example(example)
        if success:
            return {"message": f"ê´€ë ¨ ì—†ëŠ” ì˜ˆì‹œê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤: {example}"}
        else:
            return {"message": f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤: {example}"}
    except Exception as e:
        logger.error(f"âŒ ê´€ë ¨ ì—†ëŠ” ì˜ˆì‹œ ì œê±° ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

# ==================== í”¼ë“œë°± ìˆ˜ì§‘ ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/test/simple")
async def test_simple():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "í…ŒìŠ¤íŠ¸ ì„±ê³µ", "status": "ok"}

@app.get("/test/epic-list")
async def test_epic_list():
    """ì‚¬ìš© ê°€ëŠ¥í•œ Epic ëª©ë¡ ì¡°íšŒ"""
    try:
        jira = create_jira_integration()
        
        # JQLë¡œ Epic íƒ€ì… ì´ìŠˆ ì¡°íšŒ (API v3) - í˜ì´ì§• ì²˜ë¦¬ë¡œ ë” ë§ì€ Epic ì¡°íšŒ
        search_url = f"{jira.jira_url}/rest/api/3/search/jql"
        
        all_epics = []
        start_at = 0
        max_results = 100
        
        # ë¨¼ì € íŠ¹ì • í”„ë¡œì íŠ¸ì˜ Epic ì¡°íšŒ ì‹œë„
        project_epics = []
        try:
            params_project = {
                'jql': 'project = ENOMIX AND issuetype = Epic ORDER BY created ASC',
                'maxResults': 500,  # 200ì—ì„œ 500ìœ¼ë¡œ ì¦ê°€
                'fields': 'key,summary,status,resolution,created'
            }
            response_project = jira.session.get(search_url, params=params_project)
            if response_project.status_code == 200:
                project_results = response_project.json()
                project_epics = project_results.get('issues', [])
                logger.info(f"ğŸ” í”„ë¡œì íŠ¸ë³„ Epic ì¡°íšŒ: {len(project_epics)}ê°œ")
        except Exception as e:
            logger.warning(f"âš ï¸ í”„ë¡œì íŠ¸ë³„ Epic ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # í”„ë¡œì íŠ¸ë³„ ì¡°íšŒê°€ ì„±ê³µí•˜ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì•„ë‹ˆë©´ ì „ì²´ ì¡°íšŒ
        if project_epics:
            all_epics = project_epics
        else:
            while True:
                # ë‚ ì§œ ì¡°ê±´ ì—†ì´ ëª¨ë“  Epic ì¡°íšŒ (ë” ë„“ì€ ë²”ìœ„)
                params = {
                    'jql': 'issuetype = Epic ORDER BY created ASC',  # ì˜¤ë˜ëœ ê²ƒë¶€í„° ì¡°íšŒ
                    'maxResults': max_results,
                    'startAt': start_at,
                    'fields': 'key,summary,status,resolution,created'
                }
                
                response = jira.session.get(search_url, params=params)
                
                if response.status_code != 200:
                    break
                    
                results = response.json()
                issues = results.get('issues', [])
                
                if not issues:
                    break
                    
                all_epics.extend(issues)
                
                # ë” ì´ìƒ ê°€ì ¸ì˜¬ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                if len(issues) < max_results:
                    break
                    
                start_at += max_results
                
                # ìµœëŒ€ 500ê°œê¹Œì§€ë§Œ ì¡°íšŒ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
                if start_at >= 500:
                    break
        
        # ê²°ê³¼ë¥¼ response í˜•íƒœë¡œ ë³€í™˜
        response_data = {
            'issues': all_epics,
            'total': len(all_epics)
        }
        
        # Epic ëª©ë¡ ì²˜ë¦¬
        epics = []
        for issue in response_data.get('issues', []):
            epics.append({
                'key': issue['key'],
                'summary': issue['fields']['summary'],
                'status': issue['fields']['status']['name'],
                'created': issue['fields'].get('created', 'N/A')
            })
        
        # ENOMIX-7338ì´ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
        target_epic = next((epic for epic in epics if epic['key'] == 'ENOMIX-7338'), None)
        if target_epic:
            logger.info(f"âœ… ENOMIX-7338 ë°œê²¬: {target_epic}")
        else:
            logger.warning(f"âš ï¸ ENOMIX-7338ì´ ëª©ë¡ì— ì—†ìŒ. ì´ {len(epics)}ê°œ Epic ì¡°íšŒë¨")
            
            # ENOMIX-7338ì„ ì§ì ‘ ê²€ìƒ‰í•´ë³´ê¸°
            try:
                params_direct = {
                    'jql': 'key = ENOMIX-7338',
                    'maxResults': 1,
                    'fields': 'key,summary,status,issuetype,assignee,created'
                }
                response_direct = jira.session.get(search_url, params=params_direct)
                if response_direct.status_code == 200:
                    direct_results = response_direct.json()
                    if direct_results.get('total', 0) > 0:
                        direct_epic = direct_results['issues'][0]
                        logger.info(f"ğŸ” ENOMIX-7338 ì§ì ‘ ê²€ìƒ‰ ì„±ê³µ: {direct_epic['key']} - {direct_epic['fields']['summary']}")
                    else:
                        logger.warning(f"ğŸ” ENOMIX-7338 ì§ì ‘ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                else:
                    logger.warning(f"ğŸ” ENOMIX-7338 ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨: {response_direct.status_code}")
            except Exception as e:
                logger.warning(f"ğŸ” ENOMIX-7338 ì§ì ‘ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            
        return {
            "success": True,
            "epics": epics,
            "total": len(epics),
            "test_urls": [f"/test/epic-info/{epic['key']}" for epic in epics[:3]]  # í…ŒìŠ¤íŠ¸ìš© URL ì¶”ê°€
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": "Epic ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
        }

@app.get("/test/jira-connection")
async def test_jira_connection():
    """Jira ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        jira = create_jira_integration()
        connection_result = jira.test_connection()
        
        return {
            "success": connection_result,
            "message": "Jira ì—°ê²° ì„±ê³µ" if connection_result else "Jira ì—°ê²° ì‹¤íŒ¨",
            "jira_url": jira.jira_url if hasattr(jira, 'jira_url') else 'N/A',
            "username": jira.username if hasattr(jira, 'username') else 'N/A'
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "message": "Jira ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
        }

@app.get("/test/issue-all-fields/{ticket_key}")
async def test_issue_all_fields(ticket_key: str):
    """í‹°ì¼“ì˜ ëª¨ë“  í•„ë“œ ì¡°íšŒ (ë””ë²„ê¹…ìš©)"""
    try:
        logger.info(f"ğŸ” í‹°ì¼“ ì „ì²´ í•„ë“œ ì¡°íšŒ: {ticket_key}")
        
        jira = create_jira_integration()
        if not jira:
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        # API v3ë¡œ ëª¨ë“  í•„ë“œ ì¡°íšŒ
        url = f"{jira.jira_url}/rest/api/3/issue/{ticket_key}"
        
        logger.info(f"ğŸ”„ Jira API í˜¸ì¶œ: {url}")
        response = jira.session.get(url)  # í•„ë“œ ì œí•œ ì—†ìŒ (ëª¨ë“  í•„ë“œ)
        
        if response.status_code == 200:
            data = response.json()
            fields = data.get('fields', {})
            
            # customfieldë§Œ ì¶”ì¶œ
            custom_fields = {}
            for key, value in fields.items():
                if key.startswith('customfield_'):
                    custom_fields[key] = {
                        'value': value,
                        'type': type(value).__name__
                    }
            
            return {
                "success": True,
                "ticket_key": ticket_key,
                "total_fields": len(fields),
                "total_custom_fields": len(custom_fields),
                "custom_fields": custom_fields,
                "all_fields": fields  # ëª¨ë“  í•„ë“œ í¬í•¨
            }
        else:
            return JSONResponse(
                status_code=response.status_code, 
                content={"error": f"Jira API ì˜¤ë¥˜: {response.text}"}
            )
            
    except Exception as e:
        logger.error(f"âŒ í‹°ì¼“ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/test/epic-subtasks/{epic_key}")
async def test_epic_subtasks(epic_key: str):
    """Epic í•˜ìœ„ Task ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info(f"ğŸ” Epic í•˜ìœ„ Task ì¡°íšŒ ì‹œë„: {epic_key}")
        
        jira = create_jira_integration()
        result = jira.test_epic_subtasks(epic_key)
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´
        result["debug_info"] = {
            "epic_key": epic_key,
            "timestamp": str(datetime.now()),
            "jira_url": jira.jira_url if jira else "N/A"
        }
        
        return result
    except Exception as e:
        logger.error(f"âŒ Epic í•˜ìœ„ Task ì¡°íšŒ API ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e), "details": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."})

@app.get("/test/jql/{jql_query}")
async def test_jql_query(jql_query: str):
    """JQL ì¿¼ë¦¬ ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    try:
        jira = create_jira_integration()
        if not jira:
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        search_url = f"{jira.jira_url}/rest/api/3/search/jql"
        
        headers = {
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        
        params = {
            'jql': jql_query,
            'maxResults': 10,
            'fields': 'key,summary,status,issuetype,assignee',
            'expand': 'changelog'
        }
        
        logger.info(f"ğŸ” JQL í…ŒìŠ¤íŠ¸ ìš”ì²­ URL: {search_url}")
        logger.info(f"ğŸ” JQL í…ŒìŠ¤íŠ¸ ìš”ì²­ íŒŒë¼ë¯¸í„°: {params}")
        logger.info(f"ğŸ” JQL í…ŒìŠ¤íŠ¸ ìš”ì²­ í—¤ë”: {headers}")
        
        response = jira.session.get(search_url, params=params, headers=headers)
        
        return {
            "success": response.status_code == 200,
            "status_code": response.status_code,
            "jql_query": jql_query,
            "response": response.json() if response.status_code == 200 else response.text
        }
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/test/issue-id/{issue_id}")
async def test_issue_id(issue_id: str):
    """ì´ìŠˆ IDë¡œ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    try:
        jira = create_jira_integration()
        if not jira:
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        search_url = f"{jira.jira_url}/rest/api/3/search/jql"
        
        headers = {
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }
        
        params = {
            'jql': f'id = {issue_id}',
            'maxResults': 10,
            'fields': 'key,summary,status,issuetype,assignee,id',
            'expand': 'changelog'
        }
        
        logger.info(f"ğŸ” ì´ìŠˆ ID í…ŒìŠ¤íŠ¸ ìš”ì²­ URL: {search_url}")
        logger.info(f"ğŸ” ì´ìŠˆ ID í…ŒìŠ¤íŠ¸ ìš”ì²­ íŒŒë¼ë¯¸í„°: {params}")
        logger.info(f"ğŸ” ì´ìŠˆ ID í…ŒìŠ¤íŠ¸ ìš”ì²­ í—¤ë”: {headers}")
        
        response = jira.session.get(search_url, params=params, headers=headers)
        
        return {
            "success": response.status_code == 200,
            "status_code": response.status_code,
            "issue_id": issue_id,
            "response": response.json() if response.status_code == 200 else response.text
        }
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/test/permissions")
async def test_permissions():
    """í˜„ì¬ ê³„ì •ì˜ ê¶Œí•œ í™•ì¸"""
    try:
        jira = create_jira_integration()
        if not jira:
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        # í˜„ì¬ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        user_url = f"{jira.jira_url}/rest/api/3/myself"
        user_response = jira.session.get(user_url)
        
        # í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ
        projects_url = f"{jira.jira_url}/rest/api/3/project"
        projects_response = jira.session.get(projects_url)
        
        # ENOMIX í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        enomix_url = f"{jira.jira_url}/rest/api/3/project/ENOMIX"
        enomix_response = jira.session.get(enomix_url)
        
        return {
            "success": True,
            "user_info": user_response.json() if user_response.status_code == 200 else f"ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {user_response.status_code}",
            "projects": projects_response.json() if projects_response.status_code == 200 else f"í”„ë¡œì íŠ¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {projects_response.status_code}",
            "enomix_project": enomix_response.json() if enomix_response.status_code == 200 else f"ENOMIX í”„ë¡œì íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {enomix_response.status_code}",
            "user_status": user_response.status_code,
            "projects_status": projects_response.status_code,
            "enomix_status": enomix_response.status_code
        }
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/test/epic-info/{epic_key}")
async def test_epic_info(epic_key: str):
    """Epic ê¸°ë³¸ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info(f"ğŸ” Epic ì •ë³´ ì¡°íšŒ ì‹œë„: {epic_key}")
        
        # Jira ì—°ê²° í…ŒìŠ¤íŠ¸
        jira = create_jira_integration()
        connection_result = jira.test_connection()
        logger.info(f"Jira ì—°ê²° ê²°ê³¼: {connection_result}")
        
        if not connection_result:
            return {
                "success": False,
                "error": "Jira ì—°ê²° ì‹¤íŒ¨",
                "details": "Jira ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            }
        
        # Epic ì •ë³´ ì¡°íšŒ
        epic_info = jira.test_epic_basic_info(epic_key)
        logger.info(f"Epic ì •ë³´ ì¡°íšŒ ê²°ê³¼: {epic_info}")
        logger.info(f"Epic ì •ë³´ íƒ€ì…: {type(epic_info)}")
        
        if epic_info is None:
            return {
                "success": False,
                "error": "Epic ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨",
                "details": f"Epic '{epic_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Epic í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "debug_info": "epic_infoê°€ Noneìœ¼ë¡œ ë°˜í™˜ë¨"
            }
        
        if not isinstance(epic_info, dict):
            return {
                "success": False,
                "error": "Epic ì •ë³´ í˜•ì‹ ì˜¤ë¥˜",
                "details": f"ì˜ˆìƒëœ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ë°›ì€ íƒ€ì…: {type(epic_info)}",
                "debug_info": str(epic_info)
            }
        
        if 'fields' not in epic_info:
            return {
                "success": False,
                "error": "Epic ì •ë³´ í•„ë“œ ëˆ„ë½",
                "details": "Epic ì •ë³´ì— 'fields' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.",
                "debug_info": str(epic_info)
            }
        
        # Epic ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
        try:
            fields = epic_info.get('fields', {}) if epic_info else {}
            epic_title = 'N/A'
            issue_type = 'N/A'
            status = 'N/A'
            assignee = 'N/A'
            
            if fields:
                epic_title = fields.get('summary', 'N/A') if fields.get('summary') is not None else 'N/A'
                
                issue_type_obj = fields.get('issuetype')
                if issue_type_obj and isinstance(issue_type_obj, dict):
                    issue_type = issue_type_obj.get('name', 'N/A')
                
                status_obj = fields.get('status')
                if status_obj and isinstance(status_obj, dict):
                    status = status_obj.get('name', 'N/A')
                
                assignee_obj = fields.get('assignee')
                if assignee_obj and isinstance(assignee_obj, dict):
                    assignee = assignee_obj.get('displayName', 'N/A')
            
            return {
                "success": True,
                "epic_key": epic_key,
                "epic_title": epic_title,
                "issue_type": issue_type,
                "status": status,
                "assignee": assignee
            }
        except Exception as e:
            logger.error(f"âŒ Epic ì •ë³´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "error": "Epic ì •ë³´ ì²˜ë¦¬ ì˜¤ë¥˜",
                "details": f"Epic ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "debug_info": str(epic_info)
            }
    except Exception as e:
        logger.error(f"âŒ Epic ì •ë³´ ì¡°íšŒ API ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e), "details": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."})

@app.get("/test/epic-full-details/{epic_key}")
async def test_epic_full_details(epic_key: str):
    """Epicì˜ ëª¨ë“  í•„ë“œì™€ ë§í¬ ì •ë³´ ì¡°íšŒ (ìƒì„¸ ë””ë²„ê¹…ìš©)"""
    try:
        jira = create_jira_integration()
        if not jira:
            return JSONResponse(status_code=400, content={"error": "Jira ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤"})
        
        logger.info(f"ğŸ” Epic ìƒì„¸ ì •ë³´ ì¡°íšŒ: {epic_key}")
        
        # 1. Epic ìì²´ì˜ ëª¨ë“  í•„ë“œ ì¡°íšŒ
        issue_url = f"{jira.jira_url}/rest/api/3/issue/{epic_key}"
        params = {'expand': 'names,schema,operations,changelog'}
        
        epic_response = jira.session.get(issue_url, params=params)
        epic_data = epic_response.json() if epic_response.status_code == 200 else {"error": epic_response.text}
        
        # 2. Epicì˜ ë§í¬ëœ ì´ìŠˆë“¤ ì¡°íšŒ
        links_url = f"{jira.jira_url}/rest/api/3/issue/{epic_key}?fields=issuelinks"
        links_response = jira.session.get(links_url)
        links_data = links_response.json() if links_response.status_code == 200 else {"error": links_response.text}
        
        # 3. Epicì„ parentë¡œ í•˜ëŠ” í•˜ìœ„ ì´ìŠˆ ê²€ìƒ‰
        search_url = f"{jira.jira_url}/rest/api/3/search/jql"
        parent_jql = f'parent = {epic_key}'
        parent_params = {
            'jql': parent_jql,
            'maxResults': 50,
            'fields': 'key,summary,issuetype,parent'
        }
        parent_response = jira.session.get(search_url, params=parent_params)
        parent_data = parent_response.json() if parent_response.status_code == 200 else {"error": parent_response.text}
        
        # 4. Epic Link í•„ë“œë¡œ ì—°ê²°ëœ ì´ìŠˆ ê²€ìƒ‰
        epiclink_jql = f'"Epic Link" = {epic_key}'
        epiclink_params = {
            'jql': epiclink_jql,
            'maxResults': 50,
            'fields': 'key,summary,issuetype,customfield_10014,customfield_10015'
        }
        epiclink_response = jira.session.get(search_url, params=epiclink_params)
        epiclink_data = epiclink_response.json() if epiclink_response.status_code == 200 else {"error": epiclink_response.text}
        
        # 5. ëª¨ë“  ì»¤ìŠ¤í…€ í•„ë“œ ì¤‘ Epic ê´€ë ¨ í•„ë“œ ì°¾ê¸°
        fields_url = f"{jira.jira_url}/rest/api/3/field"
        fields_response = jira.session.get(fields_url)
        all_fields = fields_response.json() if fields_response.status_code == 200 else []
        
        epic_related_fields = []
        if isinstance(all_fields, list):
            for field in all_fields:
                field_name = field.get('name', '').lower()
                if 'epic' in field_name or 'parent' in field_name:
                    epic_related_fields.append({
                        'id': field.get('id'),
                        'name': field.get('name'),
                        'type': field.get('schema', {}).get('type', 'N/A')
                    })
        
        return {
            "success": True,
            "epic_key": epic_key,
            "epic_full_data": epic_data,
            "linked_issues": links_data,
            "parent_search_result": {
                "jql": parent_jql,
                "total": parent_data.get("total", 0) if isinstance(parent_data, dict) else 0,
                "issues": parent_data.get("issues", []) if isinstance(parent_data, dict) else []
            },
            "epiclink_search_result": {
                "jql": epiclink_jql,
                "total": epiclink_data.get("total", 0) if isinstance(epiclink_data, dict) else 0,
                "issues": epiclink_data.get("issues", []) if isinstance(epiclink_data, dict) else []
            },
            "epic_related_fields": epic_related_fields,
            "response_codes": {
                "epic": epic_response.status_code,
                "links": links_response.status_code,
                "parent_search": parent_response.status_code,
                "epiclink_search": epiclink_response.status_code,
                "fields": fields_response.status_code
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Epic ìƒì„¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        import traceback
        return JSONResponse(status_code=500, content={
            "error": str(e),
            "traceback": traceback.format_exc()
        })

@app.post("/feedback/")
async def collect_feedback(request: Request):
    """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘"""
    try:
        data = await request.json()
        question = data.get("question")
        feedback_type = data.get("feedback_type")
        timestamp = data.get("timestamp")
        
        logger.info(f"ğŸ“ í”¼ë“œë°± ìˆ˜ì‹ : {feedback_type} - '{question}'")
        
        # í”¼ë“œë°±ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
        if feedback_type == "helpful":
            # ë„ì›€ì´ ëœ ì§ˆë¬¸ â†’ RELATED ì˜ˆì‹œì— ì¶”ê°€
            success = intent_prompt_manager.add_related_example(question)
            if success:
                logger.info(f"âœ… RELATED ì˜ˆì‹œ ì¶”ê°€: '{question}'")
            else:
                logger.info(f"â„¹ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” RELATED ì˜ˆì‹œ: '{question}'")
                
        elif feedback_type == "not-helpful":
            # ë„ì›€ì´ ì•ˆëœ ì§ˆë¬¸ â†’ UNRELATED ì˜ˆì‹œì— ì¶”ê°€
            success = intent_prompt_manager.add_unrelated_example(question)
            if success:
                logger.info(f"âœ… UNRELATED ì˜ˆì‹œ ì¶”ê°€: '{question}'")
            else:
                logger.info(f"â„¹ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” UNRELATED ì˜ˆì‹œ: '{question}'")
                
        elif feedback_type == "wrong-classification":
            # ì˜ëª» ë¶„ë¥˜ëœ ì§ˆë¬¸ â†’ ë°˜ëŒ€ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™
            related_examples = intent_prompt_manager.get_related_examples()
            unrelated_examples = intent_prompt_manager.get_unrelated_examples()
            
            if question in related_examples:
                # RELATEDì—ì„œ UNRELATEDë¡œ ì´ë™
                intent_prompt_manager.remove_related_example(question)
                intent_prompt_manager.add_unrelated_example(question)
                logger.info(f"ğŸ”„ '{question}' RELATED â†’ UNRELATED ì´ë™")
            elif question in unrelated_examples:
                # UNRELATEDì—ì„œ RELATEDë¡œ ì´ë™
                intent_prompt_manager.remove_unrelated_example(question)
                intent_prompt_manager.add_related_example(question)
                logger.info(f"ğŸ”„ '{question}' UNRELATED â†’ RELATED ì´ë™")
            else:
                # ìƒˆë¡œìš´ ì§ˆë¬¸ì´ë©´ UNRELATEDì— ì¶”ê°€
                intent_prompt_manager.add_unrelated_example(question)
                logger.info(f"âœ… ìƒˆë¡œìš´ UNRELATED ì˜ˆì‹œ ì¶”ê°€: '{question}'")
        
        return {"message": "í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤"}
        
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/categories/migrate/")
async def migrate_categories(request: Request):
    """ì¹´í…Œê³ ë¦¬ ë³€ê²½ ì‹œ ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    try:
        data = await request.json()
        old_category = data.get("old_category")  # "ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > ì†Œë¶„ë¥˜"
        new_category = data.get("new_category")  # "ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > ì†Œë¶„ë¥˜"
        
        if not old_category or not new_category:
            return JSONResponse(status_code=400, content={"error": "old_categoryì™€ new_categoryê°€ í•„ìš”í•©ë‹ˆë‹¤"})
        
        # ì¹´í…Œê³ ë¦¬ íŒŒì‹±
        old_parts = old_category.split(' > ')
        new_parts = new_category.split(' > ')
        
        if len(old_parts) != 3 or len(new_parts) != 3:
            return JSONResponse(status_code=400, content={"error": "ì¹´í…Œê³ ë¦¬ëŠ” ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > ì†Œë¶„ë¥˜ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤"})
        
        old_major, old_minor, old_sub = old_parts
        new_major, new_minor, new_sub = new_parts
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ë°ì´í„° ì—…ë°ì´íŠ¸
        estimations = effort_manager.get_all_estimations()
        updated_count = 0
        
        for estimation in estimations:
            if (estimation.major_category == old_major and 
                estimation.minor_category == old_minor and 
                estimation.sub_category == old_sub):
                
                estimation.major_category = new_major
                estimation.minor_category = new_minor
                estimation.sub_category = new_sub
                updated_count += 1
        
        # ë³€ê²½ì‚¬í•­ ì €ì¥
        effort_manager.save_data()
        
        return {
            "message": f"{updated_count}ê°œ ë°ì´í„°ê°€ ë§ˆì´ê·¸ë ˆì´ì…˜ë˜ì—ˆìŠµë‹ˆë‹¤",
            "updated_count": updated_count
        }
        
    except Exception as e:
        logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/categories/upload-excel")
async def upload_categories_excel(file: UploadFile = File(...)):
    """ì—‘ì…€ íŒŒì¼ë¡œ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸"""
    try:
        # ì—‘ì…€ íŒŒì¼ ì½ê¸° (openpyxlë¡œ ë³‘í•©ëœ ì…€ ì²˜ë¦¬)
        contents = await file.read()
        from openpyxl import load_workbook
        
        # openpyxlë¡œ ì›Œí¬ë¶ ë¡œë“œ
        wb = load_workbook(io.BytesIO(contents))
        ws = wb.active
        
        # JSON êµ¬ì¡°ë¡œ ë³€í™˜
        categories = {}
        
        # ë³‘í•©ëœ ì…€ ì •ë³´ ìˆ˜ì§‘
        merged_ranges = list(ws.merged_cells.ranges)
        
        for row in ws.iter_rows(min_row=2, values_only=True):  # í—¤ë” ì œì™¸
            if not any(row):  # ë¹ˆ í–‰ ê±´ë„ˆë›°ê¸°
                continue
                
            # ë³‘í•©ëœ ì…€ ê°’ ì²˜ë¦¬
            major = str(row[0]).strip() if row[0] and str(row[0]).strip() != 'None' else ""
            minor = str(row[1]).strip() if row[1] and str(row[1]).strip() != 'None' else ""
            sub = str(row[2]).strip() if row[2] and str(row[2]).strip() != 'None' else ""
            
            # ë³‘í•©ëœ ì…€ì—ì„œ ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ ì´ì „ í–‰ì˜ ê°’ ì‚¬ìš©
            if not major and categories:
                # ì´ì „ ëŒ€ë¶„ë¥˜ ê°’ ì‚¬ìš©
                major = list(categories.keys())[-1] if categories else ""
            
            if not minor and major in categories and categories[major]:
                # ì´ì „ ì¤‘ë¶„ë¥˜ ê°’ ì‚¬ìš©
                minor = list(categories[major].keys())[-1] if categories[major] else ""
            
            if major and major != 'nan':
                if major not in categories:
                    categories[major] = {}
                if minor and minor != 'nan':
                    if minor not in categories[major]:
                        categories[major][minor] = []
                    if sub and sub != 'nan':
                        categories[major][minor].append(sub)
        
        # ê¸°ì¡´ íŒŒì¼ ë°±ì—…
        categories_file = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'docs', 'categories.json')
        backup_file = f"{categories_file}.backup"
        if os.path.exists(categories_file):
            shutil.copy2(categories_file, backup_file)
        
        # ìƒˆ ì¹´í…Œê³ ë¦¬ ì €ì¥
        with open(categories_file, 'w', encoding='utf-8') as f:
            json.dump(categories, f, ensure_ascii=False, indent=2)
        
        return {"success": True, "message": "ì—‘ì…€ íŒŒì¼ë¡œ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ", "categories": categories}
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "error": str(e)}

@app.get("/effort/categories/download-excel")
async def download_categories_excel():
    """í˜„ì¬ ì¹´í…Œê³ ë¦¬ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    try:
        # í˜„ì¬ ì¹´í…Œê³ ë¦¬ ë¡œë“œ
        categories_file = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'docs', 'categories.json')
        
        if not os.path.exists(categories_file):
            return JSONResponse(status_code=404, content={"error": "ì¹´í…Œê³ ë¦¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})
        
        with open(categories_file, 'r', encoding='utf-8') as f:
            categories = json.load(f)
        
        # openpyxlë¡œ ì›Œí¬ë¶ ìƒì„±
        from openpyxl import Workbook
        from openpyxl.styles import Alignment, Border, Side
        from openpyxl.utils import get_column_letter
        
        wb = Workbook()
        ws = wb.active
        ws.title = "ì¹´í…Œê³ ë¦¬"
        
        # í—¤ë” ì„¤ì •
        headers = ['ëŒ€ë¶„ë¥˜', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜']
        for col, header in enumerate(headers, 1):
            ws.cell(row=1, column=col, value=header)
        
        # ë°ì´í„° ì…ë ¥ ë° ë³‘í•© ì²˜ë¦¬
        current_row = 2
        major_start_row = 2
        minor_start_row = 2
        
        for major, minor_categories in categories.items():
            major_start_row = current_row
            
            for minor, sub_categories in minor_categories.items():
                minor_start_row = current_row
                
                for sub in sub_categories:
                    ws.cell(row=current_row, column=1, value=major)
                    ws.cell(row=current_row, column=2, value=minor)
                    ws.cell(row=current_row, column=3, value=sub)
                    current_row += 1
                
                # ì¤‘ë¶„ë¥˜ ë³‘í•© (ì†Œë¶„ë¥˜ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°)
                if current_row - minor_start_row > 1:
                    ws.merge_cells(f'B{minor_start_row}:B{current_row - 1}')
            
            # ëŒ€ë¶„ë¥˜ ë³‘í•© (ì¤‘ë¶„ë¥˜ê°€ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°)
            if current_row - major_start_row > 1:
                ws.merge_cells(f'A{major_start_row}:A{current_row - 1}')
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # ëª¨ë“  ì…€ì— í…Œë‘ë¦¬ ì ìš©
        for row in ws.iter_rows():
            for cell in row:
                cell.border = thin_border
                cell.alignment = Alignment(horizontal='center', vertical='center')
        
        # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
        for column in ws.columns:
            max_length = 0
            column_letter = get_column_letter(column[0].column)
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[column_letter].width = adjusted_width
        
        # ë©”ëª¨ë¦¬ì—ì„œ íŒŒì¼ ìƒì„±
        from io import BytesIO
        output = BytesIO()
        wb.save(output)
        output.seek(0)
        
        # íŒŒì¼ëª… ìƒì„± (í˜„ì¬ ë‚ ì§œ/ì‹œê°„ í¬í•¨)
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"categories_{timestamp}.xlsx"
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ FileResponse ë°˜í™˜
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
            tmp_file.write(output.getvalue())
            tmp_file_path = tmp_file.name
        
        return FileResponse(
            path=tmp_file_path,
            filename=filename,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/feedback/")
async def save_positive_feedback(request: Request):
    """í”¼ë“œë°± ë°ì´í„° ì €ì¥ (ê¸ì •/ë¶€ì • ëª¨ë‘ ì§€ì›)"""
    try:
        data = await request.json()
        question = data.get("question", "")
        answer = data.get("answer", "")
        sources = data.get("sources", [])
        feedback_type = data.get("feedback_type", "positive")
        user = data.get("user", "web")  # ì›¹ì—ì„œ ì˜¨ í”¼ë“œë°±ì€ "web"ìœ¼ë¡œ í‘œì‹œ
        
        logger.info(f"ğŸ’¾ í”¼ë“œë°± ì €ì¥ ìš”ì²­: {feedback_type} - {question[:50]}...")
        
        # í”¼ë“œë°± ë°ì´í„° êµ¬ì„±
        feedback_data = {
            "question": question,
            "answer": answer,
            "sources": sources,
            "timestamp": datetime.now().isoformat(),
            "feedback_type": feedback_type,
            "source": "web",  # ì›¹ì—ì„œ ì˜¨ í”¼ë“œë°±
            "user": user
        }
        
        # í”¼ë“œë°± ì €ì¥ (ê¸ì •/ë¶€ì • ëª¨ë‘ ì €ì¥)
        result = save_feedback_to_file(feedback_data)
        
        if result.get("saved"):
            feedback_count = result.get("feedback_count", 1)
            is_new = result.get("is_new", True)
            
            if is_new:
                logger.info(f"âœ… í”¼ë“œë°± ì €ì¥ ì™„ë£Œ (ìƒˆë¡œìš´ ì„¸íŠ¸): {feedback_type} - {question[:30]}...")
            else:
                logger.info(f"ğŸ“Š í”¼ë“œë°± ì¹´ìš´íŠ¸ ì¦ê°€: {feedback_type} - {question[:30]}... (ì´ {feedback_count}íšŒ)")
            
            return {
                "status": "success",
                "message": "í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
                "feedback_count": feedback_count,
                "is_new": is_new
            }
        else:
            logger.error(f"âŒ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {feedback_type} - {question[:30]}...")
            return JSONResponse(
                status_code=500,
                content={"error": "í”¼ë“œë°± ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"}
            )
        
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/effort/reindex-json/")
async def reindex_json_data(background_tasks: BackgroundTasks):
    """JSON íŒŒì¼ ê°•ì œ ì¬ì¸ë±ì‹± (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)"""
    try:
        json_file_path = os.path.join(DOCS_DIR, "effort_estimations.json")
        if not os.path.exists(json_file_path):
            return JSONResponse(status_code=404, content={"error": "effort_estimations.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})
        
        # ë°±ê·¸ë¼ìš´ë“œë¡œ ì¬ì¸ë±ì‹± ì‹¤í–‰
        background_tasks.add_task(reindex_json_background, json_file_path)
        
        logger.info("ğŸ”„ JSON íŒŒì¼ ì¬ì¸ë±ì‹± ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘")
        return {
            "status": "started", 
            "message": "ì¬ì¸ë±ì‹±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œê¹Œì§€ ìˆ˜ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        logger.error(f"âŒ JSON íŒŒì¼ ì¬ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

def reindex_json_background(json_file_path: str):
    """ì¬ì¸ë±ì‹± ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…"""
    try:
        logger.info("ğŸ“š ë°±ê·¸ë¼ìš´ë“œ ì¬ì¸ë±ì‹± ì‹œì‘...")
        start_time = time.time()
        
        result = index_json_data(json_file_path, force=True)
        
        elapsed = time.time() - start_time
        if result:
            logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ì¬ì¸ë±ì‹± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
        else:
            logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì¬ì¸ë±ì‹± ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
            
    except Exception as e:
        logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì¬ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

# StaticFiles ë§ˆìš´íŠ¸ - API ë¼ìš°íŠ¸ë“¤ ë’¤ì— ë°°ì¹˜
app.mount("/effort-management", StaticFiles(directory=os.path.join(STATIC_DIR, "effort-management")), name="effort-management")
app.mount("/category-management", StaticFiles(directory=os.path.join(STATIC_DIR, "category-management")), name="category-management")